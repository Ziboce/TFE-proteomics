{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38772,
     "status": "ok",
     "timestamp": 1741856023305,
     "user": {
      "displayName": "Jimmy Walraff",
      "userId": "17365452855707799727"
     },
     "user_tz": -60
    },
    "id": "iwsD32he_Kdi",
    "outputId": "cdadd583-8310-4393-99f2-3a50debdfaf0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, accuracy_score\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# from google.colab import drive # delete this line if not used on colab\n",
    "# drive.mount(\"/content/drive\", force_remount = True) # delete this line if not used on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "ok",
     "timestamp": 1741856028156,
     "user": {
      "displayName": "Jimmy Walraff",
      "userId": "17365452855707799727"
     },
     "user_tz": -60
    },
    "id": "Z0vzFJG__Kdm",
    "outputId": "ccd10dfc-68f2-43a0-8fc1-8522c494c808"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProteinName_SPARE</th>\n",
       "      <th>Peptide_SPARE</th>\n",
       "      <th>Status_SPARE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>VDVIPVNLPGEHGQR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>STTPDITGYR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>SYTITGLQPGTDYK</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>IYLYTLNDNAR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|P04114|APOB_HUMAN</td>\n",
       "      <td>TGISPLALIK</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>sp|P02743|SAMP_HUMAN</td>\n",
       "      <td>VGEYSLYIGR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>GQYCYELDEK</td>\n",
       "      <td>mauvais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>FEDGVLDPDYPR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>DWHGVPGQVDAAMAGR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>SIAQYWLGCPAPGHL</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ProteinName_SPARE     Peptide_SPARE Status_SPARE\n",
       "0    sp|P02751|FINC_HUMAN   VDVIPVNLPGEHGQR          bon\n",
       "1    sp|P02751|FINC_HUMAN        STTPDITGYR          bon\n",
       "2    sp|P02751|FINC_HUMAN    SYTITGLQPGTDYK          bon\n",
       "3    sp|P02751|FINC_HUMAN       IYLYTLNDNAR          bon\n",
       "4    sp|P04114|APOB_HUMAN        TGISPLALIK          bon\n",
       "..                    ...               ...          ...\n",
       "150  sp|P02743|SAMP_HUMAN        VGEYSLYIGR          bon\n",
       "151  sp|P04004|VTNC_HUMAN        GQYCYELDEK      mauvais\n",
       "152  sp|P04004|VTNC_HUMAN      FEDGVLDPDYPR          bon\n",
       "153  sp|P04004|VTNC_HUMAN  DWHGVPGQVDAAMAGR          bon\n",
       "154  sp|P04004|VTNC_HUMAN   SIAQYWLGCPAPGHL          bon\n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/data\"\n",
    "# data_path = \"/content/drive/MyDrive/TFE\"\n",
    "data_path = \"/home/jwalraff/TFE/data\"\n",
    "original_df = pd.read_csv(f'{data_path}/final_status_SPARE.csv')\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 2391,
     "status": "ok",
     "timestamp": 1741856030557,
     "user": {
      "displayName": "Jimmy Walraff",
      "userId": "17365452855707799727"
     },
     "user_tz": -60
    },
    "id": "Ws0jdTj_2m7A",
    "outputId": "b479070a-24e3-491d-a537-bbb8312bf910"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peptide</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Peptide Modified Sequence</th>\n",
       "      <th>Standard Type</th>\n",
       "      <th>First Position</th>\n",
       "      <th>Last Position</th>\n",
       "      <th>Missed Cleavages</th>\n",
       "      <th>Predicted Retention Time</th>\n",
       "      <th>Average Measured Retention Time</th>\n",
       "      <th>Peptide Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MQLVQESEEK</td>\n",
       "      <td>sp|A0A0B4J2F0|PIOS1_HUMAN</td>\n",
       "      <td>MQLVQESEEK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QPCLPIWHEMVETGGSEGVVR</td>\n",
       "      <td>sp|A0A0K2S4Q6|CD3CH_HUMAN</td>\n",
       "      <td>QPC[+57]LPIWHEMVETGGSEGVVR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VPLLLSILGAILWVNRPWR</td>\n",
       "      <td>sp|A0A0K2S4Q6|CD3CH_HUMAN</td>\n",
       "      <td>VPLLLSILGAILWVNRPWR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHPPPPEK</td>\n",
       "      <td>sp|A0A0U1RRE5|NBDY_HUMAN</td>\n",
       "      <td>SHPPPPEK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVSLLRPPFSQLPSK</td>\n",
       "      <td>sp|A0A1B0GTW7|CIROP_HUMAN</td>\n",
       "      <td>SVSLLRPPFSQLPSK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365085</th>\n",
       "      <td>ELNQYFELAK</td>\n",
       "      <td>sp|Q9Y3F1|TA6P_HUMAN</td>\n",
       "      <td>ELNQYFELAK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365086</th>\n",
       "      <td>GSFLIWLLLCWNSWYHLR</td>\n",
       "      <td>sp|Q9Y6C7|L3R2A_HUMAN</td>\n",
       "      <td>GSFLIWLLLC[+57]WNSWYHLR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365087</th>\n",
       "      <td>LCHGDSELTSGLLAT</td>\n",
       "      <td>sp|Q9Y6C7|L3R2A_HUMAN</td>\n",
       "      <td>LC[+57]HGDSELTSGLLAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365088</th>\n",
       "      <td>SCQIEQVK</td>\n",
       "      <td>sp|Q9Y6Z2|CF123_HUMAN</td>\n",
       "      <td>SC[+57]QIEQVK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365089</th>\n",
       "      <td>YSVPDTGLFQHWEGSIPT</td>\n",
       "      <td>sp|Q9Y6Z2|CF123_HUMAN</td>\n",
       "      <td>YSVPDTGLFQHWEGSIPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365090 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Peptide                    Protein  \\\n",
       "0                  MQLVQESEEK  sp|A0A0B4J2F0|PIOS1_HUMAN   \n",
       "1       QPCLPIWHEMVETGGSEGVVR  sp|A0A0K2S4Q6|CD3CH_HUMAN   \n",
       "2         VPLLLSILGAILWVNRPWR  sp|A0A0K2S4Q6|CD3CH_HUMAN   \n",
       "3                    SHPPPPEK   sp|A0A0U1RRE5|NBDY_HUMAN   \n",
       "4             SVSLLRPPFSQLPSK  sp|A0A1B0GTW7|CIROP_HUMAN   \n",
       "...                       ...                        ...   \n",
       "365085             ELNQYFELAK       sp|Q9Y3F1|TA6P_HUMAN   \n",
       "365086     GSFLIWLLLCWNSWYHLR      sp|Q9Y6C7|L3R2A_HUMAN   \n",
       "365087        LCHGDSELTSGLLAT      sp|Q9Y6C7|L3R2A_HUMAN   \n",
       "365088               SCQIEQVK      sp|Q9Y6Z2|CF123_HUMAN   \n",
       "365089     YSVPDTGLFQHWEGSIPT      sp|Q9Y6Z2|CF123_HUMAN   \n",
       "\n",
       "         Peptide Modified Sequence  Standard Type  First Position  \\\n",
       "0                       MQLVQESEEK            NaN              43   \n",
       "1       QPC[+57]LPIWHEMVETGGSEGVVR            NaN              59   \n",
       "2              VPLLLSILGAILWVNRPWR            NaN             177   \n",
       "3                         SHPPPPEK            NaN              61   \n",
       "4                  SVSLLRPPFSQLPSK            NaN              31   \n",
       "...                            ...            ...             ...   \n",
       "365085                  ELNQYFELAK            NaN              44   \n",
       "365086     GSFLIWLLLC[+57]WNSWYHLR            NaN              36   \n",
       "365087        LC[+57]HGDSELTSGLLAT            NaN              80   \n",
       "365088               SC[+57]QIEQVK            NaN              32   \n",
       "365089          YSVPDTGLFQHWEGSIPT            NaN              40   \n",
       "\n",
       "        Last Position  Missed Cleavages  Predicted Retention Time  \\\n",
       "0                  52                 0                       NaN   \n",
       "1                  79                 0                       NaN   \n",
       "2                 195                 0                       NaN   \n",
       "3                  68                 0                       NaN   \n",
       "4                  45                 0                       NaN   \n",
       "...               ...               ...                       ...   \n",
       "365085             53                 0                       NaN   \n",
       "365086             53                 0                       NaN   \n",
       "365087             94                 0                       NaN   \n",
       "365088             39                 0                       NaN   \n",
       "365089             57                 0                       NaN   \n",
       "\n",
       "        Average Measured Retention Time  Peptide Note  \n",
       "0                                   NaN           NaN  \n",
       "1                                   NaN           NaN  \n",
       "2                                   NaN           NaN  \n",
       "3                                   NaN           NaN  \n",
       "4                                   NaN           NaN  \n",
       "...                                 ...           ...  \n",
       "365085                              NaN           NaN  \n",
       "365086                              NaN           NaN  \n",
       "365087                              NaN           NaN  \n",
       "365088                              NaN           NaN  \n",
       "365089                              NaN           NaN  \n",
       "\n",
       "[365090 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_human_unique_peptide_path = f'{data_path}/Tryptic unique peptide of the human proteome.csv'\n",
    "data_human_unique_peptide = pd.read_csv(data_human_unique_peptide_path, delimiter = \";\")\n",
    "data_human_unique_peptide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset, model and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IIYbTRs_Kdn"
   },
   "outputs": [],
   "source": [
    "# Define the vocabulary\n",
    "amino_acid_vocab = {aa: idx+1 for idx, aa in enumerate(\"ACDEFGHIKLMNPQRSTVWY\")}\n",
    "\n",
    "class PeptideDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, pseudo_labels, vocab, max_len):\n",
    "        \"\"\"\n",
    "        Dataset for peptide sequences.\n",
    "\n",
    "        Args:\n",
    "            sequences (list of str): List of amino acid sequences.\n",
    "            labels (list of int): List of labels associated with the sequences.\n",
    "            pseudo_labels (list of int): List of pseudo labels associated with the sequences.\n",
    "            vocab (dict): Mapping dictionary {amino acid: index}.\n",
    "            max_len (int): Maximum sequence length (applies padding).\n",
    "        \"\"\"\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        self.pseudo_labels = pseudo_labels\n",
    "\n",
    "    def encode_sequence(self, sequence):\n",
    "        \"\"\"Encodes a sequence into integer indices with padding.\"\"\"\n",
    "        encoded = [self.vocab.get(aa, 0) for aa in sequence]  # Encodage\n",
    "        encoded += [0] * (self.max_len - len(encoded))  # Padding\n",
    "        return torch.tensor(encoded, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns an encoded sequence, its label and the pseudo label.\"\"\"\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        pseudo_label = self.pseudo_labels[idx]\n",
    "        encoded_sequence = self.encode_sequence(sequence)\n",
    "        return encoded_sequence, torch.tensor(label, dtype=torch.float32), pseudo_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1741856030608,
     "user": {
      "displayName": "Jimmy Walraff",
      "userId": "17365452855707799727"
     },
     "user_tz": -60
    },
    "id": "dfQHY6v-_Kdn",
    "outputId": "fa4a1b6f-7fb5-4386-8332-e5c660d9212b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantotypic\n",
      "0    117\n",
      "1     38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe with the sequences and labels\n",
    "df = pd.DataFrame()\n",
    "df[\"sequence\"] = original_df[\"Peptide_SPARE\"]\n",
    "df[\"quantotypic\"] = original_df.apply(lambda row: 0 if row['Status_SPARE'] == 'bon' else 1, axis=1)\n",
    "df[\"pseudo_label\"] = False\n",
    "\n",
    "positive_df = df[df['quantotypic'] == 0]\n",
    "negative_df = df[df['quantotypic'] == 1]\n",
    "\n",
    "class_counts = df['quantotypic'].value_counts()\n",
    "max_len = df['sequence'].str.len().max()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1741856031258,
     "user": {
      "displayName": "Jimmy Walraff",
      "userId": "17365452855707799727"
     },
     "user_tz": -60
    },
    "id": "-T4jtKYC9ZMH",
    "outputId": "3485a119-0c92-487c-c18d-abab08e0318e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peptide_lengths = data_human_unique_peptide[\"Peptide\"].apply(len)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(peptide_lengths, bins=np.arange(peptide_lengths.min(), peptide_lengths.max() + 2, 1), edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(\"Longueur des peptides\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Histogramme des longueurs de peptides\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1741856031326,
     "user": {
      "displayName": "Jimmy Walraff",
      "userId": "17365452855707799727"
     },
     "user_tz": -60
    },
    "id": "oXriVg7j65Pp",
    "outputId": "91db4b6f-a41d-4ec1-ad06-aed737d7f316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    MQLVQESEEK\n",
       "1         QPCLPIWHEMVETGGSEGVVR\n",
       "2           VPLLLSILGAILWVNRPWR\n",
       "3                      SHPPPPEK\n",
       "4               SVSLLRPPFSQLPSK\n",
       "                  ...          \n",
       "331077               ELNQYFELAK\n",
       "331078       GSFLIWLLLCWNSWYHLR\n",
       "331079          LCHGDSELTSGLLAT\n",
       "331080                 SCQIEQVK\n",
       "331081       YSVPDTGLFQHWEGSIPT\n",
       "Name: Peptide, Length: 331082, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_peptide = data_human_unique_peptide[\"Peptide\"]\n",
    "filtering_self_training = unique_peptide.apply(len) <= max_len\n",
    "unique_peptide = unique_peptide[filtering_self_training].reset_index(drop=True)\n",
    "unique_peptide = unique_peptide.drop_duplicates(ignore_index = True)\n",
    "unique_peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTebE4Kb_Kdo"
   },
   "outputs": [],
   "source": [
    "class PeptideMLPClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, dropout_prob, max_seq_len, num_layers):\n",
    "        \"\"\"\n",
    "        Multilayer Perceptron (MLP) classifier for peptide sequences.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Number of unique amino acids in the vocabulary.\n",
    "            embed_dim (int): Dimension of the embedding vectors.\n",
    "            hidden_dim (int): Dimension of the first hidden layer.\n",
    "            output_dim (int): Number of output classes (e.g., 1 for binary classification).\n",
    "            dropout_prob (float): Dropout probability applied after each layer.\n",
    "            max_seq_len (int): Maximum length of input sequences (used for flattening embeddings).\n",
    "            num_layers (int): Total number of hidden layers in the MLP.\n",
    "        \"\"\"\n",
    "        super(PeptideMLPClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # Input layer\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(embed_dim * max_seq_len, hidden_dim))\n",
    "\n",
    "        # Hidden layers with decreasing dimensions\n",
    "        for _ in range(num_layers - 1):\n",
    "            next_hidden_dim = max(hidden_dim // 2, output_dim)  # Prevent shrinking below output_dim\n",
    "            self.layers.append(nn.Linear(hidden_dim, next_hidden_dim))\n",
    "            hidden_dim = next_hidden_dim\n",
    "\n",
    "        # Output layer\n",
    "        self.final_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embed sequences\n",
    "        embedded = self.embedding(x)  # (batch_size, max_seq_len, embed_dim)\n",
    "\n",
    "        # Flatten embeddings\n",
    "        flattened = embedded.view(embedded.size(0), -1)  # (batch_size, embed_dim * max_seq_len)\n",
    "\n",
    "        # MLP forward pass\n",
    "        hidden = F.relu(self.layers[0](flattened))\n",
    "        hidden = self.dropout(hidden)\n",
    "\n",
    "        for layer in self.layers[1:]:\n",
    "            hidden = F.relu(layer(hidden))\n",
    "            hidden = self.dropout(hidden)\n",
    "\n",
    "        output = self.final_layer(hidden)  # (batch_size, output_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUSKIsvu_Kdq"
   },
   "outputs": [],
   "source": [
    "def compute_best(history, best_history, model, best_model):\n",
    "    \"\"\"\n",
    "    Compares the current model with the best model based on the 'pr_auc' or 'val_pr_auc' metric.\n",
    "\n",
    "    Args:\n",
    "        history (dict): Dictionary containing training and validation metrics of the current model.\n",
    "        best_history (dict): Dictionary containing the best model's validation metrics so far.\n",
    "        model (nn.Module): Current model.\n",
    "        best_model (nn.Module): Previously saved best model.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - best_model (nn.Module): Updated best model if the current model is better.\n",
    "            - best_history (dict): Updated best history if the current model is better.\n",
    "            - Better (bool): True if the current model outperformed the previous best.\n",
    "    \"\"\"\n",
    "    \n",
    "    def extract_metric_value(metric_data):\n",
    "        \"\"\"\n",
    "        Extracts the relevant metric value from a scalar or sequence.\n",
    "        Returns the last value if it is a sequence, otherwise returns the scalar value.\n",
    "        \"\"\"\n",
    "        if isinstance(metric_data, (list, tuple)):\n",
    "            return metric_data[-1]\n",
    "        if hasattr(metric_data, 'ndim'):\n",
    "            if metric_data.ndim == 0:\n",
    "                return metric_data.item()\n",
    "            return metric_data[-1]\n",
    "        return metric_data\n",
    "\n",
    "    # Select which metric to use\n",
    "    if 'pr_auc' in history:\n",
    "        metric = 'pr_auc'\n",
    "    elif 'val_pr_auc' in history:\n",
    "        metric = 'val_pr_auc'\n",
    "\n",
    "    current_metric = extract_metric_value(history[metric])\n",
    "\n",
    "    # Extract the metric from best_history if it exists\n",
    "    best_metric_value = None\n",
    "    if best_history is not None:\n",
    "        if 'pr_auc' in best_history:\n",
    "            best_metric_value = extract_metric_value(best_history['pr_auc'])\n",
    "        elif 'val_pr_auc' in best_history:\n",
    "            best_metric_value = extract_metric_value(best_history['val_pr_auc'])\n",
    "\n",
    "    Better = False\n",
    "    print(current_metric, best_metric_value)\n",
    "\n",
    "    # Update best model if current model is better\n",
    "    if best_history is None or current_metric > best_metric_value:\n",
    "        best_model = model\n",
    "        best_history = history\n",
    "        Better = True\n",
    "\n",
    "    return best_model, best_history, Better\n",
    "\n",
    "def evaluate_mlp_model(model, loader, histogram_path, plot=False):\n",
    "    \"\"\"\n",
    "    Evaluates a trained MLP model on a dataset and optionally plots a histogram of predicted probabilities.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained BiLSTM model.\n",
    "        loader (DataLoader): DataLoader providing the test data (sequence, label, pseudo-label flag).\n",
    "        histogram_path (str): Path to save the probability histogram (PNG file).\n",
    "        plot (bool, optional): If True, generates and saves a histogram of predicted probabilities. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics:\n",
    "              - 'accuracy': Classification accuracy.\n",
    "              - 'precision': Precision score.\n",
    "              - 'recall': Recall score.\n",
    "              - 'f1': F1 score.\n",
    "              - 'roc_auc': ROC AUC score.\n",
    "              - 'pr_auc': Precision-Recall AUC score.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels, _ in loader:\n",
    "            sequences = sequences.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    # Convertir les probabilités en classes pour l'accuracy\n",
    "    predicted_classes = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, predicted_classes)\n",
    "    precision = precision_score(all_targets, predicted_classes)\n",
    "    recall = recall_score(all_targets, predicted_classes)\n",
    "    f1 = f1_score(all_targets, predicted_classes)\n",
    "    roc_auc = roc_auc_score(all_targets, all_preds)\n",
    "    pr_auc = average_precision_score(all_targets, all_preds)\n",
    "\n",
    "    # Génération de l'histogramme\n",
    "    if plot:\n",
    "      plt.figure(figsize=(8, 6))\n",
    "      plt.hist(all_preds, bins=np.arange(0, 1.1, 0.1), edgecolor='black', alpha=0.7)\n",
    "      plt.xlabel(\"Predicted probabilities\")\n",
    "      plt.ylabel(\"Frequency\")\n",
    "      plt.title(\"Histogram of predicted probabilities\")\n",
    "      plt.savefig(histogram_path, bbox_inches='tight')\n",
    "      plt.close()\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc\n",
    "    }\n",
    "\n",
    "def write_into_json(dict, filename):\n",
    "    import json\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(amino_acid_vocab) + 1\n",
    "OUTPUT_DIM = 1\n",
    "def find_MLP_param(models_path=\"/content/drive/MyDrive/TFE/Models\"):\n",
    "    \"\"\"\n",
    "    Tries different hyperparameter combinations to load a MLP model from a saved state dictionary.\n",
    "\n",
    "    Args:\n",
    "        models_path (str, optional): Path to the saved model state_dict file. \n",
    "                                     Defaults to \"/content/drive/MyDrive/TFE/Models\".\n",
    "\n",
    "    Returns:\n",
    "        tuple or None: Tuple (dropout, n_layers, hidden_size, embedding_size) if a model is successfully loaded,\n",
    "                       otherwise None if no configuration works.\n",
    "    \"\"\"\n",
    "    for dropout in [0.2, 0.3]:\n",
    "        for n_layers in [1, 2, 3]:\n",
    "            for hidden_size, embedding_size in [(64, 64), (128, 128)]:\n",
    "                try:\n",
    "                    model = PeptideMLPClassifier(VOCAB_SIZE, embedding_size, \n",
    "                                            hidden_size, OUTPUT_DIM, \n",
    "                                                 dropout, max_len, n_layers)\n",
    "                    # Attempt to load model weights\n",
    "                    model.load_state_dict(torch.load(models_path))\n",
    "                    # If successful, return configuration\n",
    "                    return dropout, n_layers, hidden_size, embedding_size\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        f\"Erreur pour la config dropout={dropout}, \"\n",
    "                        f\"n_layers={n_layers}, hidden_size={hidden_size}, \"\n",
    "                        f\"embedding_size={embedding_size}.\"\n",
    "                    )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch on alpha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1944083,
     "status": "ok",
     "timestamp": 1741857989334,
     "user": {
      "displayName": "Jimmy Walraff",
      "userId": "17365452855707799727"
     },
     "user_tz": -60
    },
    "id": "cLuoVxWE_Kdq",
    "outputId": "7cb96431-507c-49c6-b8d1-a2854c88d858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_10_70.pth\n",
      "0.26657559058874847 None\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_20_70.pth\n",
      "0.4330357142857143 0.26657559058874847\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_30_70.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4780936454849498 0.4330357142857143\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_40_70.pth\n",
      "0.33958737341090284 0.4780936454849498\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_50_70.pth\n",
      "0.4365079365079365 0.4780936454849498\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_60_70.pth\n",
      "0.4225677987826325 0.4780936454849498\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_70_70.pth\n",
      "0.3521272507685551 0.4780936454849498\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_80_70.pth\n",
      "0.31933275058275057 0.4780936454849498\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_90_70.pth\n",
      "0.3786089798238136 0.4780936454849498\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_100_70.pth\n",
      "0.3215638528138528 0.4780936454849498\n",
      "Fold 2 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_10_70.pth\n",
      "0.4269438693351737 None\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_20_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_30_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_40_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_50_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_60_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_70_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_80_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_90_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_100_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "Fold 3 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_10_70.pth\n",
      "0.5996670598063787 None\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_20_70.pth\n",
      "0.5214618714618714 0.5996670598063787\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_30_70.pth\n",
      "0.5825729825729825 0.5996670598063787\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_40_70.pth\n",
      "0.5426739926739926 0.5996670598063787\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_50_70.pth\n",
      "0.5214618714618714 0.5996670598063787\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_60_70.pth\n",
      "0.5719437482595378 0.5996670598063787\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_70_70.pth\n",
      "0.515079365079365 0.5996670598063787\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_80_70.pth\n",
      "0.5569597069597069 0.5996670598063787\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_90_70.pth\n",
      "0.5109243697478991 0.5996670598063787\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_100_70.pth\n",
      "0.5502088554720134 0.5996670598063787\n",
      "Fold 4 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_10_70.pth\n",
      "0.6776695526695526 None\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_20_70.pth\n",
      "0.6647086247086247 0.6776695526695526\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_30_70.pth\n",
      "0.636002886002886 0.6776695526695526\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_40_70.pth\n",
      "0.670050505050505 0.6776695526695526\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_50_70.pth\n",
      "0.6776695526695526 0.6776695526695526\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_60_70.pth\n",
      "0.6306610056610056 0.6776695526695526\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_70_70.pth\n",
      "0.670050505050505 0.6776695526695526\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_80_70.pth\n",
      "0.670050505050505 0.6776695526695526\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_90_70.pth\n",
      "0.5526695526695526 0.6776695526695526\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_100_70.pth\n",
      "0.670050505050505 0.6776695526695526\n",
      "Fold 5 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_10_70.pth\n",
      "0.7006766381766382 None\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_20_70.pth\n",
      "0.6590099715099714 0.7006766381766382\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_30_70.pth\n",
      "0.6643518518518519 0.7006766381766382\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_40_70.pth\n",
      "0.6122867328749682 0.7006766381766382\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_50_70.pth\n",
      "0.6457692307692308 0.7006766381766382\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_60_70.pth\n",
      "0.692550505050505 0.7006766381766382\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_70_70.pth\n",
      "0.6986111111111111 0.7006766381766382\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_80_70.pth\n",
      "0.6631766381766382 0.7006766381766382\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_90_70.pth\n",
      "0.6569444444444444 0.7006766381766382\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_100_70.pth\n",
      "0.629431216931217 0.7006766381766382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN +- STD PR AUC: 0.40923433457122016 +- 0.08469270351878354\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_10_70.pth\n",
      "0.296225513616818 None\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_20_70.pth\n",
      "0.26900736139866577 0.296225513616818\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_30_70.pth\n",
      "0.3869332421964001 0.296225513616818\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_40_70.pth\n",
      "0.47352092352092345 0.3869332421964001\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_50_70.pth\n",
      "0.4458994708994709 0.47352092352092345\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_60_70.pth\n",
      "0.26294033695349484 0.47352092352092345\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_70_70.pth\n",
      "0.38947163947163943 0.47352092352092345\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_80_70.pth\n",
      "0.26900736139866577 0.47352092352092345\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_90_70.pth\n",
      "0.25010830243028387 0.47352092352092345\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_100_70.pth\n",
      "0.2518037518037518 0.47352092352092345\n",
      "Fold 2 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_10_70.pth\n",
      "0.4269438693351737 None\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_20_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_30_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_40_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_50_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_60_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_70_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_80_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_90_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_100_70.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "Fold 3 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_10_70.pth\n",
      "0.49629629629629624 None\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_20_70.pth\n",
      "0.4759120022277916 0.49629629629629624\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_30_70.pth\n",
      "0.42761568777015 0.49629629629629624\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_40_70.pth\n",
      "0.4194444444444444 0.49629629629629624\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_50_70.pth\n",
      "0.4862962962962962 0.49629629629629624\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_60_70.pth\n",
      "0.5945935545935546 0.49629629629629624\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_70_70.pth\n",
      "0.4669726247987117 0.5945935545935546\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_80_70.pth\n",
      "0.4455555555555556 0.5945935545935546\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_90_70.pth\n",
      "0.4826704014939309 0.5945935545935546\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_100_70.pth\n",
      "0.47058682058682055 0.5945935545935546\n",
      "Fold 4 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_10_70.pth\n",
      "0.6494152046783626 None\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_20_70.pth\n",
      "0.662962962962963 0.6494152046783626\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_30_70.pth\n",
      "0.6605820105820106 0.662962962962963\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_40_70.pth\n",
      "0.6783882783882784 0.662962962962963\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_50_70.pth\n",
      "0.6605820105820106 0.6783882783882784\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_60_70.pth\n",
      "0.6761904761904762 0.6783882783882784\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_70_70.pth\n",
      "0.6306610056610056 0.6783882783882784\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_80_70.pth\n",
      "0.6552579365079365 0.6783882783882784\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_90_70.pth\n",
      "0.6738095238095239 0.6783882783882784\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_100_70.pth\n",
      "0.6738095238095239 0.6783882783882784\n",
      "Fold 5 on 5 ; fixed ; 70\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_10_70.pth\n",
      "0.6835321541203894 None\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_20_70.pth\n",
      "0.6821581196581197 0.6835321541203894\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_30_70.pth\n",
      "0.6632575757575757 0.6835321541203894\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_40_70.pth\n",
      "0.6895927601809955 0.6835321541203894\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_50_70.pth\n",
      "0.6456649831649831 0.6895927601809955\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_60_70.pth\n",
      "0.7060185185185185 0.6895927601809955\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_70_70.pth\n",
      "0.692550505050505 0.7060185185185185\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_80_70.pth\n",
      "0.7006766381766382 0.7060185185185185\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_90_70.pth\n",
      "0.6932692307692307 0.7060185185185185\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_100_70.pth\n",
      "0.5899864024864026 0.7060185185185185\n",
      "\n",
      "MEAN +- STD PR AUC: 0.3745016891578268 +- 0.13044601745552128\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_10_90.pth\n",
      "0.49400380321432946 None\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_20_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_30_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_40_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_50_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_60_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_70_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_80_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_90_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_100_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "Fold 2 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_10_90.pth\n",
      "0.4269438693351737 None\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_20_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_30_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_40_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_50_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_60_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_70_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_80_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_90_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_100_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "Fold 3 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_10_90.pth\n",
      "0.6872282608695651 None\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_20_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_30_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_40_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_50_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_60_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_70_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_80_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_90_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_100_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "Fold 4 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_10_90.pth\n",
      "0.6256105006105005 None\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_20_90.pth\n",
      "0.65875 0.6256105006105005\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_30_90.pth\n",
      "0.6677489177489176 0.65875\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_40_90.pth\n",
      "0.6587301587301587 0.6677489177489176\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_50_90.pth\n",
      "0.6626984126984127 0.6677489177489176\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_60_90.pth\n",
      "0.6663690476190476 0.6677489177489176\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_70_90.pth\n",
      "0.6698412698412699 0.6677489177489176\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_80_90.pth\n",
      "0.5457692307692308 0.6698412698412699\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_90_90.pth\n",
      "0.5488095238095239 0.6698412698412699\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_100_90.pth\n",
      "0.6626984126984127 0.6698412698412699\n",
      "Fold 5 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_10_90.pth\n",
      "0.6840909090909091 None\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_20_90.pth\n",
      "0.6092171717171717 0.6840909090909091\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_30_90.pth\n",
      "0.5641025641025641 0.6840909090909091\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_40_90.pth\n",
      "0.6358058608058608 0.6840909090909091\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_50_90.pth\n",
      "0.6817460317460317 0.6840909090909091\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_60_90.pth\n",
      "0.6631766381766382 0.6840909090909091\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_70_90.pth\n",
      "0.6886904761904762 0.6840909090909091\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_80_90.pth\n",
      "0.6645927601809954 0.6886904761904762\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_90_90.pth\n",
      "0.6733058608058607 0.6886904761904762\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_100_90.pth\n",
      "0.7141025641025641 0.6886904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN +- STD PR AUC: 0.41553970428582226 +- 0.09935316105973378\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_10_90.pth\n",
      "0.49400380321432946 None\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_20_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_30_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_40_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_50_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_60_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_70_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_80_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_90_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_100_90.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "Fold 2 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_10_90.pth\n",
      "0.4269438693351737 None\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_20_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_30_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_40_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_50_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_60_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_70_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_80_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_90_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_100_90.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "Fold 3 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_10_90.pth\n",
      "0.6872282608695651 None\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_20_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_30_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_40_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_50_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_60_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_70_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_80_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_90_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_100_90.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "Fold 4 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_10_90.pth\n",
      "0.6605820105820106 None\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_20_90.pth\n",
      "0.6611408199643494 0.6605820105820106\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_30_90.pth\n",
      "0.6605820105820106 0.6611408199643494\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_40_90.pth\n",
      "0.6545214045214045 0.6611408199643494\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_50_90.pth\n",
      "0.6221139971139971 0.6611408199643494\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_60_90.pth\n",
      "0.6603084415584416 0.6611408199643494\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_70_90.pth\n",
      "0.6605820105820106 0.6611408199643494\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_80_90.pth\n",
      "0.6605820105820106 0.6611408199643494\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_90_90.pth\n",
      "0.6221139971139971 0.6611408199643494\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_100_90.pth\n",
      "0.626082251082251 0.6611408199643494\n",
      "Fold 5 on 5 ; fixed ; 90\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_10_90.pth\n",
      "0.5829517704517705 None\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_20_90.pth\n",
      "0.5837962962962963 0.5829517704517705\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_30_90.pth\n",
      "0.5944444444444444 0.5837962962962963\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_40_90.pth\n",
      "0.47799145299145296 0.5944444444444444\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_50_90.pth\n",
      "0.47845441595441596 0.5944444444444444\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_60_90.pth\n",
      "0.6643518518518519 0.5944444444444444\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_70_90.pth\n",
      "0.6226851851851851 0.6643518518518519\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_80_90.pth\n",
      "0.6706649831649831 0.6643518518518519\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_90_90.pth\n",
      "0.6470238095238094 0.6706649831649831\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_100_90.pth\n",
      "0.6092171717171717 0.6706649831649831\n",
      "\n",
      "MEAN +- STD PR AUC: 0.4211776311737491 +- 0.08044643461618319\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_10_95.pth\n",
      "0.49400380321432946 None\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_20_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_30_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_40_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_50_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_60_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_70_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_80_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_90_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_100_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "Fold 2 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_10_95.pth\n",
      "0.4269438693351737 None\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_20_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_30_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_40_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_50_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_60_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_70_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_80_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_90_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_100_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "Fold 3 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_10_95.pth\n",
      "0.6872282608695651 None\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_20_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_30_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_40_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_50_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_60_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_70_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_80_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_90_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_100_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "Fold 4 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_10_95.pth\n",
      "0.5580357142857143 None\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_20_95.pth\n",
      "0.6584249084249084 0.5580357142857143\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_30_95.pth\n",
      "0.6194444444444444 0.6584249084249084\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_40_95.pth\n",
      "0.6603084415584416 0.6584249084249084\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_50_95.pth\n",
      "0.6587301587301587 0.6603084415584416\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_60_95.pth\n",
      "0.4739010989010989 0.6603084415584416\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_70_95.pth\n",
      "0.6661904761904762 0.6603084415584416\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_80_95.pth\n",
      "0.5448412698412699 0.6661904761904762\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_90_95.pth\n",
      "0.6587301587301587 0.6661904761904762\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_100_95.pth\n",
      "0.6572067423460611 0.6661904761904762\n",
      "Fold 5 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_10_95.pth\n",
      "0.6166305916305916 None\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_20_95.pth\n",
      "0.603042328042328 0.6166305916305916\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_30_95.pth\n",
      "0.608041958041958 0.6166305916305916\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_40_95.pth\n",
      "0.5587301587301587 0.6166305916305916\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_50_95.pth\n",
      "0.5305194805194805 0.6166305916305916\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_60_95.pth\n",
      "0.5942760942760943 0.6166305916305916\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_70_95.pth\n",
      "0.6159632034632034 0.6166305916305916\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_80_95.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.620541958041958 0.6166305916305916\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_90_95.pth\n",
      "0.724074074074074 0.620541958041958\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_100_95.pth\n",
      "0.5428571428571428 0.724074074074074\n",
      "\n",
      "MEAN +- STD PR AUC: 0.43041078349713907 +- 0.09305189239593252\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_10_95.pth\n",
      "0.49400380321432946 None\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_20_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_30_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_40_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_50_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_60_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_70_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_80_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_90_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_100_95.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "Fold 2 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_10_95.pth\n",
      "0.4269438693351737 None\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_20_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_30_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_40_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_50_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_60_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_70_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_80_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_90_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_100_95.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "Fold 3 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_10_95.pth\n",
      "0.6872282608695651 None\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_20_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_30_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_40_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_50_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_60_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_70_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_80_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_90_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_100_95.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "Fold 4 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_10_95.pth\n",
      "0.662689393939394 None\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_20_95.pth\n",
      "0.6633053221288515 0.662689393939394\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_30_95.pth\n",
      "0.6545214045214045 0.6633053221288515\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_40_95.pth\n",
      "0.6216386554621849 0.6633053221288515\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_50_95.pth\n",
      "0.6552579365079365 0.6633053221288515\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_60_95.pth\n",
      "0.6216386554621849 0.6633053221288515\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_70_95.pth\n",
      "0.617063492063492 0.6633053221288515\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_80_95.pth\n",
      "0.6128547378547379 0.6633053221288515\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_90_95.pth\n",
      "0.6221139971139971 0.6633053221288515\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_100_95.pth\n",
      "0.624702380952381 0.6633053221288515\n",
      "Fold 5 on 5 ; fixed ; 95\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_10_95.pth\n",
      "0.466931216931217 None\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_20_95.pth\n",
      "0.5159632034632035 0.466931216931217\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_30_95.pth\n",
      "0.6913752913752914 0.5159632034632035\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_40_95.pth\n",
      "0.6382575757575757 0.6913752913752914\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_50_95.pth\n",
      "0.6516025641025641 0.6913752913752914\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_60_95.pth\n",
      "0.5118658574540927 0.6913752913752914\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_70_95.pth\n",
      "0.6532407407407407 0.6913752913752914\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_80_95.pth\n",
      "0.6532407407407407 0.6913752913752914\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_90_95.pth\n",
      "0.5615379990379991 0.6913752913752914\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_100_95.pth\n",
      "0.48578042328042326 0.6913752913752914\n",
      "\n",
      "MEAN +- STD PR AUC: 0.41737080193213727 +- 0.07488016019244632\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_10_99.pth\n",
      "0.49400380321432946 None\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_20_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_30_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_40_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_50_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_60_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_70_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_80_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_90_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_hard_loss_praucstop__double_loss_100_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "Fold 2 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_10_99.pth\n",
      "0.4269438693351737 None\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_20_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_30_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_40_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_50_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_60_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_70_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_80_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_90_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_hard_loss_praucstop__double_loss_100_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "Fold 3 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_10_99.pth\n",
      "0.6872282608695651 None\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_20_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_30_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_40_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_50_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_60_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_70_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_80_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_90_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_hard_loss_praucstop__double_loss_100_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "Fold 4 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_10_99.pth\n",
      "0.48928571428571427 None\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_20_99.pth\n",
      "0.48712121212121207 0.48928571428571427\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_30_99.pth\n",
      "0.4910894660894661 0.48928571428571427\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_40_99.pth\n",
      "0.575 0.4910894660894661\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_50_99.pth\n",
      "0.629978354978355 0.575\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_60_99.pth\n",
      "0.6637806637806638 0.629978354978355\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_70_99.pth\n",
      "0.5593434343434343 0.6637806637806638\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_80_99.pth\n",
      "0.6611111111111111 0.6637806637806638\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_90_99.pth\n",
      "0.479752886002886 0.6637806637806638\n",
      "BestST_MLP_Scratch_cvfold4_fixed_hard_loss_praucstop__double_loss_100_99.pth\n",
      "0.5726190476190476 0.6637806637806638\n",
      "Fold 5 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_10_99.pth\n",
      "0.49929653679653685 None\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_20_99.pth\n",
      "0.4711233211233211 0.49929653679653685\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_30_99.pth\n",
      "0.513558201058201 0.49929653679653685\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_40_99.pth\n",
      "0.46338383838383834 0.513558201058201\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_50_99.pth\n",
      "0.6446581196581196 0.513558201058201\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_60_99.pth\n",
      "0.7149470899470899 0.6446581196581196\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_70_99.pth\n",
      "0.4362960568842922 0.7149470899470899\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_80_99.pth\n",
      "0.5608076563958917 0.7149470899470899\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_90_99.pth\n",
      "0.6471861471861471 0.7149470899470899\n",
      "BestST_MLP_Scratch_cvfold5_fixed_hard_loss_praucstop__double_loss_100_99.pth\n",
      "0.5671296296296297 0.7149470899470899\n",
      "\n",
      "MEAN +- STD PR AUC: 0.42396314013173253 +- 0.09021469657528233\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_10_99.pth\n",
      "0.49400380321432946 None\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_20_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_30_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_40_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_50_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_60_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_70_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_80_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_90_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "BestST_MLP_Scratch_cvfold1_fixed_soft_loss_praucstop__double_loss_100_99.pth\n",
      "0.49400380321432946 0.49400380321432946\n",
      "Fold 2 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_10_99.pth\n",
      "0.4269438693351737 None\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_20_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_30_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_40_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_50_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_60_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_70_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_80_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_90_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "BestST_MLP_Scratch_cvfold2_fixed_soft_loss_praucstop__double_loss_100_99.pth\n",
      "0.4269438693351737 0.4269438693351737\n",
      "Fold 3 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_10_99.pth\n",
      "0.6872282608695651 None\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_20_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_30_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_40_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_50_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_60_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_70_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_80_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_90_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "BestST_MLP_Scratch_cvfold3_fixed_soft_loss_praucstop__double_loss_100_99.pth\n",
      "0.6872282608695651 0.6872282608695651\n",
      "Fold 4 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_10_99.pth\n",
      "0.6145937395937396 None\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_20_99.pth\n",
      "0.6240196078431373 0.6145937395937396\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_30_99.pth\n",
      "0.6466386554621849 0.6240196078431373\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_40_99.pth\n",
      "0.6701298701298701 0.6466386554621849\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_50_99.pth\n",
      "0.6594691857849753 0.6701298701298701\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_60_99.pth\n",
      "0.6531746031746032 0.6701298701298701\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_70_99.pth\n",
      "0.6611111111111111 0.6701298701298701\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_80_99.pth\n",
      "0.6611111111111111 0.6701298701298701\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_90_99.pth\n",
      "0.6434640522875817 0.6701298701298701\n",
      "BestST_MLP_Scratch_cvfold4_fixed_soft_loss_praucstop__double_loss_100_99.pth\n",
      "0.6626984126984127 0.6701298701298701\n",
      "Fold 5 on 5 ; fixed ; 99\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_10_99.pth\n",
      "0.5753968253968254 None\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_20_99.pth\n",
      "0.37886141636141635 0.5753968253968254\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_30_99.pth\n",
      "0.34271094402673347 0.5753968253968254\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_40_99.pth\n",
      "0.4321581196581197 0.5753968253968254\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_50_99.pth\n",
      "0.42696927255750783 0.5753968253968254\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_60_99.pth\n",
      "0.37987053795877324 0.5753968253968254\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_70_99.pth\n",
      "0.5356060606060605 0.5753968253968254\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_80_99.pth\n",
      "0.4719169719169719 0.5753968253968254\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_90_99.pth\n",
      "0.4946581196581197 0.5753968253968254\n",
      "BestST_MLP_Scratch_cvfold5_fixed_soft_loss_praucstop__double_loss_100_99.pth\n",
      "0.41784228843052373 0.5753968253968254\n",
      "\n",
      "MEAN +- STD PR AUC: 0.41008852985638694 +- 0.06664927189383273\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.455026455026455 None\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_20_00_Maxiter5.pth\n",
      "0.46092314118629907 0.455026455026455\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.42479769685652036 0.46092314118629907\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.431036556036556 0.46092314118629907\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.455026455026455 0.46092314118629907\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.4539267062486876 0.46092314118629907\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.4466230936819172 0.46092314118629907\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_80_00_Maxiter5.pth\n",
      "0.4633597883597883 0.46092314118629907\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.46090880796763145 0.4633597883597883\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.4633597883597883 0.4633597883597883\n",
      "Fold 2 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.4017195767195767 None\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_20_00_Maxiter5.pth\n",
      "0.39768692564745195 0.4017195767195767\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.3958486903533343 0.4017195767195767\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.4254647034252297 0.4017195767195767\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.34606481481481477 0.4254647034252297\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.4254647034252297 0.4254647034252297\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.3403276182881446 0.4254647034252297\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_80_00_Maxiter5.pth\n",
      "0.34619883040935673 0.4254647034252297\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.30975783475783475 0.4254647034252297\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.4237103174603174 0.4254647034252297\n",
      "Fold 3 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.5068452380952381 None\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_20_00_Maxiter5.pth\n",
      "0.4766865079365079 0.5068452380952381\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.4766865079365079 0.5068452380952381\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.4846230158730158 0.5068452380952381\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.47254572118702554 0.5068452380952381\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.4825396825396826 0.5068452380952381\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.48015873015873023 0.5068452380952381\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_80_00_Maxiter5.pth\n",
      "0.47601794340924775 0.5068452380952381\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.48870573870573863 0.5068452380952381\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.5156687675070027 0.5068452380952381\n",
      "Fold 4 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.6521942110177404 None\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_20_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6521942110177404\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6521942110177404\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6521942110177404\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.6473063973063973 0.6521942110177404\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6521942110177404\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.6521942110177404 0.6521942110177404\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_80_00_Maxiter5.pth\n",
      "0.6521942110177404 0.6521942110177404\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6521942110177404\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6521942110177404\n",
      "Fold 5 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.5973124098124097 None\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_20_00_Maxiter5.pth\n",
      "0.5215909090909091 0.5973124098124097\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.6595811051693404 0.5973124098124097\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.6092171717171717 0.6595811051693404\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.6888740344622697 0.6595811051693404\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.6282679738562091 0.6888740344622697\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.6569444444444444 0.6888740344622697\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_80_00_Maxiter5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6345811051693404 0.6888740344622697\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.6472073677956031 0.6888740344622697\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.6508838383838383 0.6888740344622697\n",
      "\n",
      "MEAN +- STD PR AUC: 0.4409406516821113 +- 0.14325836168781553\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.4322629125260704 None\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_20_00_Maxiter5.pth\n",
      "0.38011063011063007 0.4322629125260704\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.36411318150448585 0.4322629125260704\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.4934704184704185 0.4322629125260704\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.4889361047449282 0.4934704184704185\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.48703703703703705 0.4934704184704185\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.48296957671957674 0.4934704184704185\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_80_00_Maxiter5.pth\n",
      "0.4332852332852333 0.4934704184704185\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.3223764868266147 0.4934704184704185\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.29279495724508514 0.4934704184704185\n",
      "Fold 2 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.394343891402715 None\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_20_00_Maxiter5.pth\n",
      "0.3885144485144485 0.394343891402715\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.3933862433862434 0.394343891402715\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.394094304388422 0.394343891402715\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.37576097105508866 0.394343891402715\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.37395721925133685 0.394343891402715\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.3741269841269841 0.394343891402715\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_80_00_Maxiter5.pth\n",
      "0.3692143401983219 0.394343891402715\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.37588137009189637 0.394343891402715\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.37576097105508866 0.394343891402715\n",
      "Fold 3 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.5594326768239811 None\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_20_00_Maxiter5.pth\n",
      "0.5659141583054627 0.5594326768239811\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.5441530691530692 0.5659141583054627\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.5149882323795367 0.5659141583054627\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.5544210218123262 0.5659141583054627\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.555026455026455 0.5659141583054627\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.534219001610306 0.5659141583054627\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_80_00_Maxiter5.pth\n",
      "0.5515542328042328 0.5659141583054627\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.49725977347460726 0.5659141583054627\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.534219001610306 0.5659141583054627\n",
      "Fold 4 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.6500297088532383 None\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_20_00_Maxiter5.pth\n",
      "0.6521942110177404 0.6500297088532383\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.6530934343434344 0.6521942110177404\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6530934343434344\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.6473063973063973 0.6530934343434344\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6530934343434344\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6530934343434344\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_80_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6530934343434344\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.6500297088532383 0.6530934343434344\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.6530934343434344 0.6530934343434344\n",
      "Fold 5 on 5 ; TopK ; 00\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_10_00_Maxiter5.pth\n",
      "0.604025549613785 None\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_20_00_Maxiter5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6152777777777778 0.604025549613785\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_30_00_Maxiter5.pth\n",
      "0.5180555555555555 0.6152777777777778\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_40_00_Maxiter5.pth\n",
      "0.6345811051693404 0.6152777777777778\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_50_00_Maxiter5.pth\n",
      "0.5734427609427609 0.6345811051693404\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_60_00_Maxiter5.pth\n",
      "0.6508838383838383 0.6345811051693404\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_70_00_Maxiter5.pth\n",
      "0.692550505050505 0.6508838383838383\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_80_00_Maxiter5.pth\n",
      "0.6632575757575757 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_90_00_Maxiter5.pth\n",
      "0.6508838383838383 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_100_00_Maxiter5.pth\n",
      "0.6319444444444444 0.692550505050505\n",
      "\n",
      "MEAN +- STD PR AUC: 0.41648186854046376 +- 0.13526387990905953\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.42479769685652036 None\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_20_01_Maxiter5.pth\n",
      "0.450410972469796 0.42479769685652036\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.4501388274608089 0.450410972469796\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.359459579172865 0.450410972469796\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.42397352103234454 0.450410972469796\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.45257547463429815 0.450410972469796\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.44418644650842787 0.45257547463429815\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_80_01_Maxiter5.pth\n",
      "0.46159211159211166 0.45257547463429815\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.455026455026455 0.46159211159211166\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.46119528619528616 0.46159211159211166\n",
      "Fold 2 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.28568376068376067 None\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_20_01_Maxiter5.pth\n",
      "0.33608058608058605 0.28568376068376067\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.3003016591251885 0.33608058608058605\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.32019654751852894 0.33608058608058605\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.2972222222222222 0.33608058608058605\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.3355263157894737 0.33608058608058605\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.32192460317460314 0.33608058608058605\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_80_01_Maxiter5.pth\n",
      "0.3235884485884486 0.33608058608058605\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.3194444444444444 0.33608058608058605\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.3141905480140774 0.33608058608058605\n",
      "Fold 3 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.495734126984127 None\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_20_01_Maxiter5.pth\n",
      "0.5024743230625583 0.495734126984127\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.4998168498168498 0.5024743230625583\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.4865412365412366 0.5024743230625583\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.5048433048433049 0.5024743230625583\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.501010101010101 0.5048433048433049\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.4913632119514473 0.5048433048433049\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_80_01_Maxiter5.pth\n",
      "0.5167341430499325 0.5048433048433049\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.5024743230625583 0.5167341430499325\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.4920634920634921 0.5167341430499325\n",
      "Fold 4 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.6605339105339105 None\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_20_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.6572447160682454 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.5665584415584416 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_80_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.6221139971139971 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6605339105339105\n",
      "Fold 5 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.5543803418803419 None\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_20_01_Maxiter5.pth\n",
      "0.6393518518518518 0.5543803418803419\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.622207367795603 0.6393518518518518\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.6508838383838383 0.6393518518518518\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.5154914529914529 0.6508838383838383\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.6127645502645502 0.6508838383838383\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.5386904761904762 0.6508838383838383\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_80_01_Maxiter5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6359126984126984 0.6508838383838383\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.377991452991453 0.6508838383838383\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.5066530691530692 0.6508838383838383\n",
      "\n",
      "MEAN +- STD PR AUC: 0.44432415737654135 +- 0.11976212824384468\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.38824950269963054 None\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_20_01_Maxiter5.pth\n",
      "0.2515873015873016 0.38824950269963054\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.23835978835978838 0.38824950269963054\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.22126577126577127 0.38824950269963054\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.23420479302832245 0.38824950269963054\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.23915343915343917 0.38824950269963054\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.43964099196297335 0.38824950269963054\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_80_01_Maxiter5.pth\n",
      "0.2842889681124975 0.43964099196297335\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.23394024276377218 0.43964099196297335\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.24182742209057997 0.43964099196297335\n",
      "Fold 2 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.394978354978355 None\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_20_01_Maxiter5.pth\n",
      "0.3701917989417989 0.394978354978355\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.3426806858008904 0.394978354978355\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.3613196033562166 0.394978354978355\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.3426936026936027 0.394978354978355\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.3493932748538011 0.394978354978355\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.29061934844543535 0.394978354978355\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_80_01_Maxiter5.pth\n",
      "0.33740259740259737 0.394978354978355\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.3535912698412698 0.394978354978355\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.337014047800661 0.394978354978355\n",
      "Fold 3 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.5409141583054626 None\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_20_01_Maxiter5.pth\n",
      "0.48059310680794054 0.5409141583054626\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.5079365079365079 0.5409141583054626\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.4836568322981366 0.5409141583054626\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.5002978502978503 0.5409141583054626\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.5071428571428571 0.5409141583054626\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.4659391534391535 0.5409141583054626\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_80_01_Maxiter5.pth\n",
      "0.5363247863247863 0.5409141583054626\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.4658730158730159 0.5409141583054626\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.5343434343434343 0.5409141583054626\n",
      "Fold 4 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.6552579365079365 None\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_20_01_Maxiter5.pth\n",
      "0.6135912698412698 0.6552579365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6552579365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.6134135472370766 0.6581439393939393\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.6500297088532383 0.6581439393939393\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6581439393939393\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.6550802139037433 0.6581439393939393\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_80_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6581439393939393\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.6550802139037433 0.6581439393939393\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.6581439393939393 0.6581439393939393\n",
      "Fold 5 on 5 ; TopK ; 01\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_10_01_Maxiter5.pth\n",
      "0.49803113553113554 None\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_20_01_Maxiter5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5180555555555555 0.49803113553113554\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_30_01_Maxiter5.pth\n",
      "0.4449074074074074 0.5180555555555555\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_40_01_Maxiter5.pth\n",
      "0.3985750360750361 0.5180555555555555\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_50_01_Maxiter5.pth\n",
      "0.5623316498316498 0.5180555555555555\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_60_01_Maxiter5.pth\n",
      "0.5901094276094276 0.5623316498316498\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_70_01_Maxiter5.pth\n",
      "0.4930555555555556 0.5901094276094276\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_80_01_Maxiter5.pth\n",
      "0.4549242424242424 0.5901094276094276\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_90_01_Maxiter5.pth\n",
      "0.44212962962962965 0.5901094276094276\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_100_01_Maxiter5.pth\n",
      "0.5763888888888888 0.5901094276094276\n",
      "\n",
      "MEAN +- STD PR AUC: 0.4086196027750649 +- 0.14583038317132466\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.45956136077619447 None\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.4398289618877854 0.45956136077619447\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.3622754767256046 0.45956136077619447\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.4495550745550746 0.45956136077619447\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.47270322270322274 0.45956136077619447\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.4479458450046685 0.47270322270322274\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.48723155929038287 0.47270322270322274\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.3077342047930283 0.48723155929038287\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.451635625010238 0.48723155929038287\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_hard_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.451635625010238 0.48723155929038287\n",
      "Fold 2 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.2846153846153846 None\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.3104957907589487 0.2846153846153846\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.34673659673659674 0.3104957907589487\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.34294871794871795 0.34673659673659674\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.29626577126577125 0.34673659673659674\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.3280936454849498 0.34673659673659674\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.3031339031339031 0.34673659673659674\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.33028662794109015 0.34673659673659674\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.3094504830917874 0.34673659673659674\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_hard_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.4198444872357916 0.34673659673659674\n",
      "Fold 3 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.4689270152505446 None\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.49371827003405944 0.4689270152505446\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.5214285714285715 0.49371827003405944\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.5299603174603175 0.5214285714285715\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.4936507936507937 0.5299603174603175\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.526984126984127 0.5299603174603175\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.5024743230625583 0.5299603174603175\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.5061507936507936 0.5299603174603175\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.4913632119514473 0.5299603174603175\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_hard_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.49503968253968256 0.5299603174603175\n",
      "Fold 4 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.5535714285714286 None\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.4757048507048507 0.5535714285714286\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.5572344322344323 0.5535714285714286\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.4821428571428571 0.5572344322344323\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.6210317460317459 0.5572344322344323\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.617063492063492 0.6210317460317459\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.5572344322344323 0.6210317460317459\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.4739010989010989 0.6210317460317459\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.47786935286935284 0.6210317460317459\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_hard_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.48928571428571427 0.6210317460317459\n",
      "Fold 5 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.5516806722689076 None\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.5823412698412699 0.5516806722689076\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.5604076479076479 0.5823412698412699\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.4661616161616161 0.5823412698412699\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.5988247863247863 0.5823412698412699\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.5882940588822941 0.5988247863247863\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.6072362278244631 0.5988247863247863\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.6013888888888889 0.6072362278244631\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.6072362278244631 0.6072362278244631\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_hard_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.6109126984126984 0.6072362278244631\n",
      "\n",
      "MEAN +- STD PR AUC: 0.43270941100681143 +- 0.10528591132739813\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.26792102806034696 None\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.2875116713352007 0.26792102806034696\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.2377622979016168 0.2875116713352007\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.3970760233918128 0.2875116713352007\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.3160675381263616 0.3970760233918128\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.2611021016593772 0.3970760233918128\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.30182132682132684 0.3970760233918128\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.392885623148781 0.3970760233918128\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.2938608776844071 0.3970760233918128\n",
      "BestST_MLP_Scratch_cvfold1_TopK_fixed_soft_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.3354358117516012 0.3970760233918128\n",
      "Fold 2 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.3797079772079772 None\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.27024897807506504 0.3797079772079772\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.27676098458707155 0.3797079772079772\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.28432974432974434 0.3797079772079772\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.27395268177876875 0.3797079772079772\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.3631837606837607 0.3797079772079772\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.2903654970760234 0.3797079772079772\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.2507323232323232 0.3797079772079772\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.36870370370370364 0.3797079772079772\n",
      "BestST_MLP_Scratch_cvfold2_TopK_fixed_soft_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.2878174603174603 0.3797079772079772\n",
      "Fold 3 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.4843915343915344 None\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.514102564102564 0.4843915343915344\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.46669637551990495 0.514102564102564\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.4405794369029663 0.514102564102564\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.41786881419234356 0.514102564102564\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.4304591607223186 0.514102564102564\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.39435564435564435 0.514102564102564\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.3942564745196324 0.514102564102564\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.4410830999066293 0.514102564102564\n",
      "BestST_MLP_Scratch_cvfold3_TopK_fixed_soft_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.5159632034632035 0.514102564102564\n",
      "Fold 4 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.6576388888888889 None\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.6522921522921523 0.6576388888888889\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.6587301587301587 0.6576388888888889\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.6565656565656566 0.6587301587301587\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.6605339105339105 0.6587301587301587\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.6210317460317459 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.6626984126984127 0.6605339105339105\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.6656611362493715 0.6626984126984127\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.6634374397532292 0.6656611362493715\n",
      "BestST_MLP_Scratch_cvfold4_TopK_fixed_soft_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.6587301587301587 0.6656611362493715\n",
      "Fold 5 on 5 ; TopK ; 05\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_10_05_Maxiter5.pth\n",
      "0.4893790849673203 None\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_20_05_Maxiter5.pth\n",
      "0.4930555555555556 0.4893790849673203\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_30_05_Maxiter5.pth\n",
      "0.6266025641025641 0.4930555555555556\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_40_05_Maxiter5.pth\n",
      "0.4766025641025641 0.6266025641025641\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_50_05_Maxiter5.pth\n",
      "0.6404914529914529 0.6266025641025641\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_60_05_Maxiter5.pth\n",
      "0.5016025641025641 0.6404914529914529\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_70_05_Maxiter5.pth\n",
      "0.558041958041958 0.6404914529914529\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_80_05_Maxiter5.pth\n",
      "0.5562594268476622 0.6404914529914529\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_90_05_Maxiter5.pth\n",
      "0.5276879982762336 0.6404914529914529\n",
      "BestST_MLP_Scratch_cvfold5_TopK_fixed_soft_loss_praucstop__double_loss_100_05_Maxiter5.pth\n",
      "0.5529914529914529 0.6404914529914529\n",
      "\n",
      "MEAN +- STD PR AUC: 0.4426303202774326 +- 0.11337248048369263\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_10_01.pth\n",
      "0.42662362427808653 None\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_20_01.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343091168091168 0.42662362427808653\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_30_01.pth\n",
      "0.44937034642916995 0.42662362427808653\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_40_01.pth\n",
      "0.44797432529630676 0.44937034642916995\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_50_01.pth\n",
      "0.45547438672438667 0.44937034642916995\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_60_01.pth\n",
      "0.3545893719806763 0.45547438672438667\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_70_01.pth\n",
      "0.4466230936819172 0.45547438672438667\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_80_05.pth\n",
      "0.44375 0.45547438672438667\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_90_01.pth\n",
      "0.44965682465682466 0.45547438672438667\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_hard_loss_praucstop__double_loss_100_01.pth\n",
      "0.3692421413009648 0.45547438672438667\n",
      "Fold 2 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_10_01.pth\n",
      "0.29477124183006537 None\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_20_01.pth\n",
      "0.2969642242862057 0.29477124183006537\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_30_01.pth\n",
      "0.27419733975461535 0.2969642242862057\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_40_01.pth\n",
      "0.30179615705931495 0.2969642242862057\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_50_01.pth\n",
      "0.2827485380116959 0.30179615705931495\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_60_01.pth\n",
      "0.31346153846153846 0.30179615705931495\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_70_01.pth\n",
      "0.2869332421964001 0.31346153846153846\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_80_01.pth\n",
      "0.3096450934686229 0.31346153846153846\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_90_01.pth\n",
      "0.29947089947089944 0.31346153846153846\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_hard_loss_praucstop__double_loss_100_01.pth\n",
      "0.34892957919273704 0.31346153846153846\n",
      "Fold 3 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_10_01.pth\n",
      "0.5214618714618714 None\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_20_01.pth\n",
      "0.4865412365412366 0.5214618714618714\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_30_01.pth\n",
      "0.5095571095571095 0.5214618714618714\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_40_01.pth\n",
      "0.48650793650793656 0.5214618714618714\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_50_01.pth\n",
      "0.46665274296853243 0.5214618714618714\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_60_01.pth\n",
      "0.4823412698412698 0.5214618714618714\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_70_01.pth\n",
      "0.514102564102564 0.5214618714618714\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_80_01.pth\n",
      "0.4841269841269842 0.5214618714618714\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_90_01.pth\n",
      "0.48870573870573863 0.5214618714618714\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_hard_loss_praucstop__double_loss_100_01.pth\n",
      "0.48789098972922496 0.5214618714618714\n",
      "Fold 4 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_10_01.pth\n",
      "0.6164772727272727 None\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_20_01.pth\n",
      "0.6550802139037433 0.6164772727272727\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_30_01.pth\n",
      "0.6550802139037433 0.6550802139037433\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_40_05.pth\n",
      "0.4821428571428571 0.6550802139037433\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_50_01.pth\n",
      "0.6603084415584416 0.6550802139037433\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_60_01.pth\n",
      "0.6550802139037433 0.6603084415584416\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_70_01.pth\n",
      "0.5643939393939393 0.6603084415584416\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_80_01.pth\n",
      "0.5609217171717171 0.6603084415584416\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_90_01.pth\n",
      "0.6581439393939393 0.6603084415584416\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_hard_loss_praucstop__double_loss_100_01.pth\n",
      "0.6500297088532383 0.6603084415584416\n",
      "Fold 5 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_10_01.pth\n",
      "0.5953282828282829 None\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_20_01.pth\n",
      "0.3902777777777778 0.5953282828282829\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_30_01.pth\n",
      "0.45535714285714285 0.5953282828282829\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_40_01.pth\n",
      "0.43302987861811393 0.5953282828282829\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_50_01.pth\n",
      "0.5827020202020202 0.5953282828282829\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_60_01.pth\n",
      "0.6404914529914529 0.5953282828282829\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_70_01.pth\n",
      "0.5899864024864026 0.6404914529914529\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_80_01.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692550505050505 0.6404914529914529\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_90_01.pth\n",
      "0.6154914529914529 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_hard_loss_praucstop__double_loss_100_01.pth\n",
      "0.6099358974358974 0.692550505050505\n",
      "\n",
      "MEAN +- STD PR AUC: 0.43514709207685864 +- 0.122454199407718\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_10_05.pth\n",
      "0.3085139318885449 None\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_20_01.pth\n",
      "0.22243265993265993 0.3085139318885449\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_30_01.pth\n",
      "0.24190069190069188 0.3085139318885449\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_40_01.pth\n",
      "0.25502645502645505 0.3085139318885449\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_50_01.pth\n",
      "0.25968456494772285 0.3085139318885449\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_60_01.pth\n",
      "0.28139312378442816 0.3085139318885449\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_70_01.pth\n",
      "0.36680549412747554 0.3085139318885449\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_80_01.pth\n",
      "0.23642171668487458 0.36680549412747554\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_90_01.pth\n",
      "0.26846405228758163 0.36680549412747554\n",
      "BestST_MLP_Scratch_cvfold1_TopK_evo_soft_loss_praucstop__double_loss_100_01.pth\n",
      "0.22592592592592595 0.36680549412747554\n",
      "Fold 2 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_10_01.pth\n",
      "0.38965201465201466 None\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_20_01.pth\n",
      "0.24 0.38965201465201466\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_30_01.pth\n",
      "0.2798504273504273 0.38965201465201466\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_40_01.pth\n",
      "0.36925611129272456 0.38965201465201466\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_50_01.pth\n",
      "0.3584210526315789 0.38965201465201466\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_60_01.pth\n",
      "0.35731654014262704 0.38965201465201466\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_70_01.pth\n",
      "0.3660161738422608 0.38965201465201466\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_80_01.pth\n",
      "0.34246212121212116 0.38965201465201466\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_90_01.pth\n",
      "0.35385756056808687 0.38965201465201466\n",
      "BestST_MLP_Scratch_cvfold2_TopK_evo_soft_loss_praucstop__double_loss_100_01.pth\n",
      "0.3678985507246377 0.38965201465201466\n",
      "Fold 3 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_10_01.pth\n",
      "0.5667508417508417 None\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_20_01.pth\n",
      "0.5268115942028986 0.5667508417508417\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_30_01.pth\n",
      "0.5114718614718615 0.5667508417508417\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_40_01.pth\n",
      "0.48650793650793656 0.5667508417508417\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_50_01.pth\n",
      "0.48563311688311683 0.5667508417508417\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_60_01.pth\n",
      "0.5200918964076858 0.5667508417508417\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_70_01.pth\n",
      "0.504978354978355 0.5667508417508417\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_80_01.pth\n",
      "0.4770895770895771 0.5667508417508417\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_90_01.pth\n",
      "0.5091645353793691 0.5667508417508417\n",
      "BestST_MLP_Scratch_cvfold3_TopK_evo_soft_loss_praucstop__double_loss_100_01.pth\n",
      "0.47944647944647945 0.5667508417508417\n",
      "Fold 4 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_10_05.pth\n",
      "0.665079365079365 None\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_20_05.pth\n",
      "0.6608058608058608 0.665079365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_30_05.pth\n",
      "0.6587301587301587 0.665079365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_40_01.pth\n",
      "0.6186417748917749 0.665079365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_50_01.pth\n",
      "0.6626984126984127 0.665079365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_60_01.pth\n",
      "0.6581439393939393 0.665079365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_70_05.pth\n",
      "0.6626984126984127 0.665079365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_80_01.pth\n",
      "0.6581439393939393 0.665079365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_90_01.pth\n",
      "0.6616161616161615 0.665079365079365\n",
      "BestST_MLP_Scratch_cvfold4_TopK_evo_soft_loss_praucstop__double_loss_100_01.pth\n",
      "0.6581439393939393 0.665079365079365\n",
      "Fold 5 on 5 ; TopK ; evo\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_10_01.pth\n",
      "0.43302987861811393 None\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_20_01.pth\n",
      "0.5827020202020202 0.43302987861811393\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_30_01.pth\n",
      "0.6151094276094276 0.5827020202020202\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_40_01.pth\n",
      "0.4340099715099715 0.6151094276094276\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_50_01.pth\n",
      "0.434553872053872 0.6151094276094276\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_60_01.pth\n",
      "0.4827020202020202 0.6151094276094276\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_70_01.pth\n",
      "0.6077020202020202 0.6151094276094276\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_80_01.pth\n",
      "0.43825757575757573 0.6151094276094276\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_90_01.pth\n",
      "0.5549242424242424 0.6151094276094276\n",
      "BestST_MLP_Scratch_cvfold5_TopK_evo_soft_loss_praucstop__double_loss_100_01.pth\n",
      "0.5549242424242424 0.6151094276094276\n",
      "\n",
      "MEAN +- STD PR AUC: 0.4276605377582269 +- 0.14063360861858354\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_50.pth\n",
      "0.504940235203393 None\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5052123802123802 0.504940235203393\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_20.pth\n",
      "0.5059808612440191 0.5052123802123802\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_30.pth\n",
      "0.5045893719806763 0.5059808612440191\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_40.pth\n",
      "0.5101546601546602 0.5059808612440191\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_60.pth\n",
      "0.5027472527472527 0.5101546601546602\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_70.pth\n",
      "0.5191468253968253 0.5101546601546602\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_80.pth\n",
      "0.4961683053788317 0.5191468253968253\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_90.pth\n",
      "0.5159416971916971 0.5191468253968253\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_hard_loss_praucstop__double_loss_100.pth\n",
      "0.507317759639741 0.5191468253968253\n",
      "Fold 2 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_50.pth\n",
      "0.32576383591829816 None\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_10.pth\n",
      "0.32681159420289857 0.32576383591829816\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_20.pth\n",
      "0.3327082803627426 0.32681159420289857\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_30.pth\n",
      "0.3465971692516315 0.3327082803627426\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_40.pth\n",
      "0.3410416136960759 0.3465971692516315\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_60.pth\n",
      "0.3410416136960759 0.3465971692516315\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_70.pth\n",
      "0.29798605814052037 0.3465971692516315\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_80.pth\n",
      "0.33687494702940923 0.3465971692516315\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_90.pth\n",
      "0.31662640901771333 0.3465971692516315\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_hard_loss_praucstop__double_loss_100.pth\n",
      "0.32576383591829816 0.3465971692516315\n",
      "Fold 3 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_50.pth\n",
      "0.5659063159063159 None\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_10.pth\n",
      "0.5561660561660562 0.5659063159063159\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_20.pth\n",
      "0.5955537518037518 0.5659063159063159\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_30.pth\n",
      "0.5593434343434344 0.5955537518037518\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_40.pth\n",
      "0.654001554001554 0.5955537518037518\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_60.pth\n",
      "0.654001554001554 0.654001554001554\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_70.pth\n",
      "0.5375180375180375 0.654001554001554\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_80.pth\n",
      "0.5420967920967921 0.654001554001554\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_90.pth\n",
      "0.6214618714618714 0.654001554001554\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_hard_loss_praucstop__double_loss_100.pth\n",
      "0.6268037518037518 0.654001554001554\n",
      "Fold 4 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_50.pth\n",
      "0.6672771672771672 None\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_10.pth\n",
      "0.6672771672771672 0.6672771672771672\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_20.pth\n",
      "0.6723276723276723 0.6672771672771672\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_30.pth\n",
      "0.6723276723276723 0.6723276723276723\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_40.pth\n",
      "0.6723276723276723 0.6723276723276723\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_60.pth\n",
      "0.6723276723276723 0.6723276723276723\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_70.pth\n",
      "0.6723276723276723 0.6723276723276723\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_80.pth\n",
      "0.6723276723276723 0.6723276723276723\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_90.pth\n",
      "0.6723276723276723 0.6723276723276723\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_hard_loss_praucstop__double_loss_100.pth\n",
      "0.6723276723276723 0.6723276723276723\n",
      "Fold 5 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_50.pth\n",
      "0.6643518518518519 None\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_10.pth\n",
      "0.6986111111111111 0.6643518518518519\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_20.pth\n",
      "0.6925505050505051 0.6986111111111111\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_30.pth\n",
      "0.692550505050505 0.6986111111111111\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_40.pth\n",
      "0.6932692307692307 0.6986111111111111\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_60.pth\n",
      "0.6932692307692307 0.6986111111111111\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_70.pth\n",
      "0.6925505050505051 0.6986111111111111\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_80.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7060185185185185 0.6986111111111111\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_90.pth\n",
      "0.6986111111111111 0.7060185185185185\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_hard_loss_praucstop__double_loss_100.pth\n",
      "0.6986111111111111 0.7060185185185185\n",
      "\n",
      "MEAN +- STD PR AUC: 0.44358955379050374 +- 0.10574681062310613\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_10.pth\n",
      "0.2774170274170274 None\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_20.pth\n",
      "0.33582258814456956 0.2774170274170274\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_30.pth\n",
      "0.35380266906582697 0.33582258814456956\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_40.pth\n",
      "0.4049719887955182 0.35380266906582697\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_50.pth\n",
      "0.4181746031746032 0.4049719887955182\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_60.pth\n",
      "0.4353790093921672 0.4181746031746032\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_70.pth\n",
      "0.43653641679957467 0.4353790093921672\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_80.pth\n",
      "0.3160667834580878 0.43653641679957467\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_90.pth\n",
      "0.5105263157894736 0.43653641679957467\n",
      "BestST_MLP_Scratch_cvfold1_optimal_pr_soft_loss_praucstop__double_loss_100.pth\n",
      "0.4484205408118451 0.5105263157894736\n",
      "Fold 2 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_10.pth\n",
      "0.30501976284584975 None\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_20.pth\n",
      "0.271517094017094 0.30501976284584975\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_30.pth\n",
      "0.2275017253278123 0.30501976284584975\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_40.pth\n",
      "0.26804972804972804 0.30501976284584975\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_50.pth\n",
      "0.2856053176419309 0.30501976284584975\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_60.pth\n",
      "0.2706458034718904 0.30501976284584975\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_70.pth\n",
      "0.3964646464646464 0.30501976284584975\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_80.pth\n",
      "0.24271164021164018 0.3964646464646464\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_90.pth\n",
      "0.24820158102766798 0.3964646464646464\n",
      "BestST_MLP_Scratch_cvfold2_optimal_pr_soft_loss_praucstop__double_loss_100.pth\n",
      "0.28804131054131055 0.3964646464646464\n",
      "Fold 3 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_10.pth\n",
      "0.46737053795877326 None\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_20.pth\n",
      "0.33252639173691806 0.46737053795877326\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_30.pth\n",
      "0.5972222222222222 0.46737053795877326\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_40.pth\n",
      "0.36706349206349204 0.5972222222222222\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_50.pth\n",
      "0.5213815789473684 0.5972222222222222\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_60.pth\n",
      "0.4772005772005772 0.5972222222222222\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_70.pth\n",
      "0.43108465608465607 0.5972222222222222\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_80.pth\n",
      "0.5050802139037434 0.5972222222222222\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_90.pth\n",
      "0.528968253968254 0.5972222222222222\n",
      "BestST_MLP_Scratch_cvfold3_optimal_pr_soft_loss_praucstop__double_loss_100.pth\n",
      "0.5191290191290191 0.5972222222222222\n",
      "Fold 4 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_10.pth\n",
      "0.6572447160682454 None\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_20.pth\n",
      "0.6633053221288515 0.6572447160682454\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_30.pth\n",
      "0.6663690476190477 0.6633053221288515\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_40.pth\n",
      "0.6633053221288515 0.6663690476190477\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_50.pth\n",
      "0.6663690476190477 0.6663690476190477\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_60.pth\n",
      "0.6663690476190477 0.6663690476190477\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_70.pth\n",
      "0.6738095238095239 0.6663690476190477\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_80.pth\n",
      "0.6783882783882784 0.6738095238095239\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_90.pth\n",
      "0.6738095238095239 0.6783882783882784\n",
      "BestST_MLP_Scratch_cvfold4_optimal_pr_soft_loss_praucstop__double_loss_100.pth\n",
      "0.6723276723276723 0.6783882783882784\n",
      "Fold 5 on 5 ; optimal ; pr\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_10.pth\n",
      "0.6932692307692307 None\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_20.pth\n",
      "0.7027777777777778 0.6932692307692307\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_30.pth\n",
      "0.692550505050505 0.7027777777777778\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_40.pth\n",
      "0.6863247863247863 0.7027777777777778\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_50.pth\n",
      "0.7060185185185185 0.7027777777777778\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_60.pth\n",
      "0.6986111111111111 0.7060185185185185\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_70.pth\n",
      "0.6986111111111111 0.7060185185185185\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_80.pth\n",
      "0.6821581196581197 0.7060185185185185\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_90.pth\n",
      "0.6784816490698844 0.7060185185185185\n",
      "BestST_MLP_Scratch_cvfold5_optimal_pr_soft_loss_praucstop__double_loss_100.pth\n",
      "0.7027777777777778 0.7060185185185185\n",
      "\n",
      "MEAN +- STD PR AUC: 0.47850705688395756 +- 0.09338278308417598\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_50.pth\n",
      "0.4100212652844232 None\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_10.pth\n",
      "0.3812680375180375 0.4100212652844232\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_20.pth\n",
      "0.4281639194139194 0.4100212652844232\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_30.pth\n",
      "0.3702756464904803 0.4281639194139194\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_40.pth\n",
      "0.32676686059039 0.4281639194139194\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_60.pth\n",
      "0.5073211875843454 0.4281639194139194\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_70.pth\n",
      "0.3722519310754605 0.5073211875843454\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_80.pth\n",
      "0.46986111111111106 0.5073211875843454\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_90.pth\n",
      "0.32067247188730563 0.5073211875843454\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_hard_loss_praucstop__double_loss_100.pth\n",
      "0.34309343434343437 0.5073211875843454\n",
      "Fold 2 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_50.pth\n",
      "0.2847375792422232 None\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_10.pth\n",
      "0.2551184725097769 0.2847375792422232\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_20.pth\n",
      "0.2866868969810146 0.2847375792422232\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_30.pth\n",
      "0.29477124183006537 0.2866868969810146\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_40.pth\n",
      "0.318287037037037 0.29477124183006537\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_60.pth\n",
      "0.3128654970760234 0.318287037037037\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_70.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3961988304093567 0.318287037037037\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_80.pth\n",
      "0.28134920634920635 0.3961988304093567\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_90.pth\n",
      "0.3959942562883739 0.3961988304093567\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_hard_loss_praucstop__double_loss_100.pth\n",
      "0.3978328173374613 0.3961988304093567\n",
      "Fold 3 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_50.pth\n",
      "0.6316727053140097 None\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_10.pth\n",
      "0.6305852644087938 0.6316727053140097\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_20.pth\n",
      "0.6278619528619528 0.6316727053140097\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_30.pth\n",
      "0.6336489898989899 0.6316727053140097\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_40.pth\n",
      "0.6391131815044858 0.6336489898989899\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_60.pth\n",
      "0.6258856682769726 0.6391131815044858\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_70.pth\n",
      "0.6351449275362319 0.6391131815044858\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_80.pth\n",
      "0.6336489898989899 0.6391131815044858\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_90.pth\n",
      "0.6391131815044858 0.6391131815044858\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_hard_loss_praucstop__double_loss_100.pth\n",
      "0.6391131815044858 0.6391131815044858\n",
      "Fold 4 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_50.pth\n",
      "0.570054945054945 None\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_10.pth\n",
      "0.5654761904761905 0.570054945054945\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_20.pth\n",
      "0.6603084415584416 0.570054945054945\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_30.pth\n",
      "0.6672771672771672 0.6603084415584416\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_40.pth\n",
      "0.6677489177489178 0.6672771672771672\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_60.pth\n",
      "0.6234459984459984 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_70.pth\n",
      "0.6672771672771672 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_80.pth\n",
      "0.6651126651126651 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_90.pth\n",
      "0.6631363805276849 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_hard_loss_praucstop__double_loss_100.pth\n",
      "0.6637806637806638 0.6677489177489178\n",
      "Fold 5 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_50.pth\n",
      "0.692550505050505 None\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_10.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_20.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_30.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_40.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_60.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_70.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_80.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_90.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_hard_loss_praucstop__double_loss_100.pth\n",
      "0.692550505050505 0.692550505050505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN +- STD PR AUC: 0.41278155236524094 +- 0.12156896763970723\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n",
      "Fold 1 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_10.pth\n",
      "0.3798102281848412 None\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_20.pth\n",
      "0.4223214285714285 0.3798102281848412\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_30.pth\n",
      "0.4164086687306502 0.4223214285714285\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_40.pth\n",
      "0.24161097187412978 0.4223214285714285\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_50.pth\n",
      "0.3919823232323232 0.4223214285714285\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_60.pth\n",
      "0.32465149802611104 0.4223214285714285\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_70.pth\n",
      "0.40048100048100044 0.4223214285714285\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_80.pth\n",
      "0.4045751633986928 0.4223214285714285\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_90.pth\n",
      "0.3965277777777778 0.4223214285714285\n",
      "BestST_MLP_Scratch_cvfold1_optimal_roc_soft_loss_praucstop__double_loss_100.pth\n",
      "0.2837586390217969 0.4223214285714285\n",
      "Fold 2 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_10.pth\n",
      "0.41666666666666663 None\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_20.pth\n",
      "0.39796650717703347 0.41666666666666663\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_30.pth\n",
      "0.4100877192982456 0.41666666666666663\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_40.pth\n",
      "0.4017543859649123 0.41666666666666663\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_50.pth\n",
      "0.4237103174603174 0.41666666666666663\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_60.pth\n",
      "0.4003474595579859 0.4237103174603174\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_70.pth\n",
      "0.3996362433862434 0.4237103174603174\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_80.pth\n",
      "0.4237103174603174 0.4237103174603174\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_90.pth\n",
      "0.4254647034252297 0.4237103174603174\n",
      "BestST_MLP_Scratch_cvfold2_optimal_roc_soft_loss_praucstop__double_loss_100.pth\n",
      "0.39779800809212573 0.4254647034252297\n",
      "Fold 3 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_10.pth\n",
      "0.6336489898989899 None\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_20.pth\n",
      "0.6316727053140097 0.6336489898989899\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_30.pth\n",
      "0.6114267676767676 0.6336489898989899\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_40.pth\n",
      "0.6083630421865716 0.6336489898989899\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_50.pth\n",
      "0.6105275443510737 0.6336489898989899\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_60.pth\n",
      "0.6027307852965748 0.6336489898989899\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_70.pth\n",
      "0.5877622979016167 0.6336489898989899\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_80.pth\n",
      "0.5881944444444445 0.6336489898989899\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_90.pth\n",
      "0.5851307189542483 0.6336489898989899\n",
      "BestST_MLP_Scratch_cvfold3_optimal_roc_soft_loss_praucstop__double_loss_100.pth\n",
      "0.5877622979016167 0.6336489898989899\n",
      "Fold 4 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_10.pth\n",
      "0.6603084415584416 None\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_20.pth\n",
      "0.6677489177489178 0.6603084415584416\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_30.pth\n",
      "0.6637806637806638 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_40.pth\n",
      "0.6677489177489178 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_50.pth\n",
      "0.6596398770311813 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_60.pth\n",
      "0.6637806637806638 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_70.pth\n",
      "0.6651126651126651 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_80.pth\n",
      "0.6672771672771672 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_90.pth\n",
      "0.6655844155844156 0.6677489177489178\n",
      "BestST_MLP_Scratch_cvfold4_optimal_roc_soft_loss_praucstop__double_loss_100.pth\n",
      "0.6651126651126651 0.6677489177489178\n",
      "Fold 5 on 5 ; optimal ; roc\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_10.pth\n",
      "0.692550505050505 None\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_20.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_30.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_40.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_50.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_60.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_70.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_80.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_90.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "BestST_MLP_Scratch_cvfold5_optimal_roc_soft_loss_praucstop__double_loss_100.pth\n",
      "0.692550505050505 0.692550505050505\n",
      "\n",
      "MEAN +- STD PR AUC: 0.4223368709170832 +- 0.0914980121036565\n",
      "\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "=============================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jwalraff/anaconda3/envs/deep/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "VOCAB_SIZE = len(amino_acid_vocab) + 1  # +1 for padding\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1\n",
    "BATCH_SIZE = 32\n",
    "LSTM_LAYERS = 2\n",
    "LSTM_HIDDEN_DIM = 32\n",
    "N_EPOCHS = 100\n",
    "N_SPLITS = 5\n",
    "DROPOUT = 0.3\n",
    "\n",
    "count = 1\n",
    "do_early_stopping = True\n",
    "weighting = True\n",
    "oversampling = False\n",
    "FT = None\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "models_path = \"/home/jwalraff/TFE/Models\"\n",
    "results_path = \"/home/jwalraff/TFE/Results\"\n",
    "images_path = \"/home/jwalraff/TFE/Images\"\n",
    "\n",
    "imbalanced_name_dict = {\n",
    "    \"Imbalance\": {\n",
    "        (False, False): \"N\",\n",
    "        (True, False): \"W\",\n",
    "        (False, True): \"O\"\n",
    "    },\n",
    "    \"Early Stopping\": {\n",
    "        True: \"ES\",\n",
    "        False: \"NES\"\n",
    "    },\n",
    "    \"Transfer Learning\": {\n",
    "        True: \"FT\",\n",
    "        False: \"FE\",\n",
    "        None: \"N\"\n",
    "    }\n",
    "}\n",
    "\n",
    "self_training_technique = {\n",
    "    \"fixed\": ['70', '90', '95', '99'],\n",
    "    \"TopK\": ['00', '01', '05', 'evo'],\n",
    "    \"optimal\": ['pr', 'roc']\n",
    "}\n",
    "\n",
    "alphas = np.arange(10, 110, 10)\n",
    "\n",
    "for tech, values in self_training_technique.items():\n",
    "    for v in values:\n",
    "        for soft in ['hard', 'soft']:\n",
    "            kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "            \n",
    "            fold_metrics = []\n",
    "            \n",
    "            for fold, (train_idx, test_idx) in enumerate(kf.split(df, df['quantotypic'])):\n",
    "                print(f\"Fold {fold+1} on 5 ; {tech} ; {v}\")\n",
    "\n",
    "                best_model = None\n",
    "                best_res = None\n",
    "                best_filename = None\n",
    "                \n",
    "                for filename in os.listdir(f\"{models_path}/SelfTraining/MLP\"):\n",
    "                    if f\"fold{fold+1}\" in filename and \"double_loss\" in filename and \"praucstop\" in filename and soft in filename:\n",
    "                        if tech in filename and (tech != 'fixed' or 'TopK' not in filename):\n",
    "                            value = filename.split(\"_\")[-1].replace(\".pth\", \"\") if (tech == 'fixed') else filename.split(\"_\")[-2]\n",
    "                            if value == v or (tech=='optimal' and f\"{tech}_{v}\" in filename) or (v=='evo' and v in filename):\n",
    "                                print(filename)\n",
    "                                \n",
    "                                dropout, n_layers, hidden_size, embedding_size = find_MLP_param(f\"{models_path}/SelfTraining/MLP/{filename}\", verbose=False)\n",
    "                                model = PeptideMLPClassifier(VOCAB_SIZE, embedding_size, hidden_size, OUTPUT_DIM, dropout, max_len, n_layers)\n",
    "                                model.load_state_dict(torch.load(f\"{models_path}/SelfTraining/MLP/{filename}\"))\n",
    "                                \n",
    "                                tmp_train_df = df.iloc[train_idx]\n",
    "                                test_df = df.iloc[test_idx]\n",
    "                                \n",
    "                                train_df, val_df = train_test_split(tmp_train_df, test_size = 0.2, stratify=tmp_train_df[\"quantotypic\"], random_state=42)\n",
    "                                \n",
    "                                val_dataset = PeptideDataset(val_df['sequence'].values, val_df['quantotypic'].values, train_df[\"pseudo_label\"].values, amino_acid_vocab, max_len)\n",
    "                                validation_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "                                test_dataset = PeptideDataset(test_df['sequence'].values, test_df['quantotypic'].values, test_df[\"pseudo_label\"].values, amino_acid_vocab, max_len)\n",
    "                                test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "                                \n",
    "                                res_val = evaluate_mlp_model(model, validation_loader, amino_acid_vocab, max_len, f\"{images_path}/SelfTraining/MLP/MLPOutputProbabilities_fold{fold+1}\", plot=False)\n",
    "                                # print(res_val)\n",
    "                                best_model, best_res, better = compute_best(res_val, best_res, model, best_model)\n",
    "                                \n",
    "                                if better:\n",
    "                                    best_filename = filename\n",
    "\n",
    "                res_test = evaluate_mlp_model(model, test_loader, amino_acid_vocab, max_len, f\"{images_path}/SelfTraining/MLP/MLPOutputProbabilities_fold{fold+1}\", plot=False)\n",
    "                \n",
    "                fold_metrics.append({\n",
    "                    \"accuracy\": res_test.get(\"accuracy\"),\n",
    "                    \"precision\": res_test.get(\"precision\"),\n",
    "                    \"recall\": res_test.get(\"recall\"),\n",
    "                    \"f1\": res_test.get(\"f1\"),\n",
    "                    \"roc_auc\": res_test.get(\"roc_auc\"),\n",
    "                    \"pr_auc\": res_test.get(\"pr_auc\"),\n",
    "                })\n",
    "            \n",
    "            summary = {\n",
    "                \"tech\": tech,\n",
    "                \"v\": v,\n",
    "                \"soft\": soft,\n",
    "                \"metrics\": {}\n",
    "            }\n",
    "            \n",
    "            for metric in [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\", \"pr_auc\"]:\n",
    "                values = [m[metric] for m in fold_metrics if m[metric] is not None]\n",
    "                summary[\"metrics\"][f\"{metric}_mean\"] = np.mean(values) if values else None\n",
    "                summary[\"metrics\"][f\"{metric}_std\"] = np.std(values) if values else None\n",
    "\n",
    "            save_fname = best_filename.replace(\".pth\", \"\").replace(\"_Maxiter5\", \"\").replace(\"_cvfold5\", \"\").replace(\"__\", \"_\")\n",
    "            write_into_json(summary, f\"{results_path}/SelfTraining/MLP/GridSearch/GridSearch_CVSummary_{save_fname}.json\")\n",
    "\n",
    "            print()\n",
    "            print(\"MEAN +- STD PR AUC:\", summary[\"metrics\"][\"pr_auc_mean\"], \"+-\", summary[\"metrics\"][\"pr_auc_std\"])\n",
    "            print(\"\\n=============================================================================================================\")\n",
    "            print(\"=============================================================================================================\")\n",
    "            print(\"=============================================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 54 better models compared to baseline\n",
      "There are 196 worse models compared to baseline\n"
     ]
    }
   ],
   "source": [
    "results_path = \"/home/jwalraff/TFE/Results\"\n",
    "\n",
    "better_res = 0\n",
    "worse_res = 0\n",
    "baseline = {\"pr_auc_mean\": 0.43456442433228143, \"pr_auc_std\": 0.10431544252930217, \"roc_auc_mean\": 0.6143374741200829, \"roc_auc_std\": 0.11738902214599607}\n",
    "\n",
    "count = 0\n",
    "\n",
    "for filename in os.listdir(f\"{results_path}/SelfTraining/MLP\"):\n",
    "    if \"CVSummary\" in filename:\n",
    "        with open(f\"{results_path}/SelfTraining/MLP/{filename}\", 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "            if data[\"metrics\"][\"pr_auc_mean\"] > baseline[\"pr_auc_mean\"]:\n",
    "                better_res += 1\n",
    "            elif data[\"metrics\"][\"pr_auc_mean\"] < baseline[\"pr_auc_mean\"]:\n",
    "                worse_res += 1\n",
    "\n",
    "\n",
    "for filename in os.listdir(f\"{results_path}/SelfTraining/MLP/GridSearch\"):\n",
    "    if \"CVSummary\" in filename:\n",
    "        with open(f\"{results_path}/SelfTraining/MLP/GridSearch/{filename}\", 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "            if data[\"metrics\"][\"pr_auc_mean\"] > baseline[\"pr_auc_mean\"]:\n",
    "                better_res += 1\n",
    "            elif data[\"metrics\"][\"pr_auc_mean\"] < baseline[\"pr_auc_mean\"]:\n",
    "                worse_res += 1\n",
    "\n",
    "print()\n",
    "print(f\"There are {better_res} better models compared to baseline\")\n",
    "print(f\"There are {worse_res} worse models compared to baseline\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch_CVSummary_BestST_MLP_Scratch_fixed_hard_loss_praucstop_double_loss_10_70.json\n",
      "\n",
      "10\n",
      "\n",
      "fixed ; 70 ; hard_loss ; double_loss ; praucstop ; [True, True, True, True, True, True, True, True, True, True]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_fixed_soft_loss_praucstop_double_loss_60_70.json\n",
      "\n",
      "10\n",
      "\n",
      "fixed ; 70 ; soft_loss ; double_loss ; praucstop ; [False, True, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_fixed_hard_loss_praucstop_double_loss_100_90.json\n",
      "\n",
      "10\n",
      "\n",
      "fixed ; 90 ; hard_loss ; double_loss ; praucstop ; [False, True, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_fixed_soft_loss_praucstop_double_loss_80_90.json\n",
      "\n",
      "10\n",
      "\n",
      "fixed ; 90 ; soft_loss ; double_loss ; praucstop ; [True, True, True, True, True, False, True, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_fixed_hard_loss_praucstop_double_loss_90_95.json\n",
      "\n",
      "10\n",
      "\n",
      "fixed ; 95 ; hard_loss ; double_loss ; praucstop ; [False, False, False, False, False, False, True, True, True, True]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_fixed_soft_loss_praucstop_double_loss_30_95.json\n",
      "\n",
      "10\n",
      "\n",
      "fixed ; 95 ; soft_loss ; double_loss ; praucstop ; [True, False, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_fixed_hard_loss_praucstop_double_loss_60_99.json\n",
      "\n",
      "10\n",
      "\n",
      "fixed ; 99 ; hard_loss ; double_loss ; praucstop ; [False, False, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_fixed_soft_loss_praucstop_double_loss_10_99.json\n",
      "\n",
      "10\n",
      "\n",
      "fixed ; 99 ; soft_loss ; double_loss ; praucstop ; [False, False, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_TopK_fixed_hard_loss_praucstop_double_loss_50_00.json\n",
      "\n",
      "10\n",
      "\n",
      "TopK_fixed ; 00 ; hard_loss ; double_loss ; praucstop ; [False, False, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_TopK_fixed_soft_loss_praucstop_double_loss_70_00.json\n",
      "\n",
      "10\n",
      "\n",
      "TopK_fixed ; 00 ; soft_loss ; double_loss ; praucstop ; [False, False, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_TopK_fixed_hard_loss_praucstop_double_loss_40_01.json\n",
      "\n",
      "10\n",
      "\n",
      "TopK_fixed ; 01 ; hard_loss ; double_loss ; praucstop ; [False, False, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_TopK_fixed_soft_loss_praucstop_double_loss_60_01.json\n",
      "\n",
      "10\n",
      "\n",
      "TopK_fixed ; 01 ; soft_loss ; double_loss ; praucstop ; [False, False, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_TopK_fixed_hard_loss_praucstop_double_loss_100_05.json\n",
      "\n",
      "10\n",
      "\n",
      "TopK_fixed ; 05 ; hard_loss ; double_loss ; praucstop ; [False, False, True, True, True, True, True, True, True, True]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_TopK_fixed_soft_loss_praucstop_double_loss_50_05.json\n",
      "\n",
      "10\n",
      "\n",
      "TopK_fixed ; 05 ; soft_loss ; double_loss ; praucstop ; [True, True, True, True, True, True, True, True, True, True]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_TopK_evo_hard_loss_praucstop_double_loss_80_01.json\n",
      "\n",
      "10\n",
      "\n",
      "TopK_evo ; None ; hard_loss ; double_loss ; praucstop ; [True, True, True, True, True, True, True, True, True, True]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_TopK_evo_soft_loss_praucstop_double_loss_30_01.json\n",
      "\n",
      "10\n",
      "\n",
      "TopK_evo ; None ; soft_loss ; double_loss ; praucstop ; [False, True, True, True, True, True, True, True, True, True]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_optimal_pr_hard_loss_praucstop_double_loss_80.json\n",
      "\n",
      "10\n",
      "\n",
      "optimal_pr ; None ; hard_loss ; double_loss ; praucstop ; [False, False, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_optimal_pr_soft_loss_praucstop_double_loss_50.json\n",
      "\n",
      "10\n",
      "\n",
      "optimal_pr ; None ; soft_loss ; double_loss ; praucstop ; [True, True, True, True, True, True, True, True, True, True]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_optimal_roc_hard_loss_praucstop_double_loss_50.json\n",
      "\n",
      "10\n",
      "\n",
      "optimal_roc ; None ; hard_loss ; double_loss ; praucstop ; [False, False, False, False, False, False, False, False, False, False]\n",
      "GridSearch_CVSummary_BestST_MLP_Scratch_optimal_roc_soft_loss_praucstop_double_loss_10.json\n",
      "\n",
      "10\n",
      "\n",
      "optimal_roc ; None ; soft_loss ; double_loss ; praucstop ; [True, True, True, True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "results_path = \"/home/jwalraff/TFE/Results\"\n",
    "\n",
    "for filename in os.listdir(f\"{results_path}/SelfTraining/MLP/GridSearch\"):\n",
    "    print(filename)\n",
    "    v = None\n",
    "    if \"TopK\" in filename:\n",
    "        if \"evo\" in filename:\n",
    "            pl_method = \"TopK_evo\"\n",
    "        else:\n",
    "            v = filename.split(\"_\")[-1].replace('.json', '')\n",
    "            pl_method = \"TopK_fixed\"\n",
    "    elif \"fixed\" in filename:\n",
    "        v = filename.split(\"_\")[-1].replace('.json', '')\n",
    "        pl_method = \"fixed\"\n",
    "    else:\n",
    "        pl_method = \"optimal_roc\" if \"roc\" in filename else \"optimal_pr\"\n",
    "        \n",
    "    label_type = \"hard_loss\" if \"hard\" in filename else \"soft_loss\"\n",
    "    dl = \"double_loss\"\n",
    "    praucstop = \"praucstop\"\n",
    "    \n",
    "    with open(f\"{results_path}/SelfTraining/MLP/GridSearch/{filename}\", 'r') as ff:\n",
    "        baseline_data = json.load(ff)\n",
    "    \n",
    "    res_arrays = []\n",
    "    is_better_than_baseline = []\n",
    "    for f in os.listdir(f\"{results_path}/SelfTraining/MLP\"):\n",
    "        if label_type in f and praucstop in f and dl in f and \"CVSummary\" in f:\n",
    "            if pl_method in f and (pl_method != 'fixed' or 'TopK' not in f):\n",
    "                if v is not None and v in f.split(\"_\")[-1]:\n",
    "                    res_arrays.append(f)\n",
    "                    with open(f\"{results_path}/SelfTraining/MLP/{f}\", 'r') as fff:\n",
    "                        data = json.load(fff)\n",
    "                elif v is None:\n",
    "                    res_arrays.append(res_arrays)\n",
    "                    with open(f\"{results_path}/SelfTraining/MLP/{f}\", 'r') as fff:\n",
    "                        data = json.load(fff)\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                if baseline_data[\"metrics\"][\"pr_auc_mean\"] > data[\"metrics\"][\"pr_auc_mean\"]:\n",
    "                    is_better_than_baseline.append(True)\n",
    "                else:\n",
    "                    is_better_than_baseline.append(False)\n",
    "\n",
    "    print()\n",
    "    print(len(res_arrays))\n",
    "    print()\n",
    "    print(f\"{pl_method} ; {v} ; {label_type} ; {dl} ; {praucstop} ; {is_better_than_baseline}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:deep]",
   "language": "python",
   "name": "conda-env-deep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
