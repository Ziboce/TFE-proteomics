{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peptdeep.pretrained_models import ModelManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/\")\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProteinName_SPARE</th>\n",
       "      <th>Peptide_SPARE</th>\n",
       "      <th>Status_SPARE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>VDVIPVNLPGEHGQR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>STTPDITGYR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>SYTITGLQPGTDYK</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>IYLYTLNDNAR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|P04114|APOB_HUMAN</td>\n",
       "      <td>TGISPLALIK</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>sp|P02743|SAMP_HUMAN</td>\n",
       "      <td>VGEYSLYIGR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>GQYCYELDEK</td>\n",
       "      <td>mauvais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>FEDGVLDPDYPR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>DWHGVPGQVDAAMAGR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>SIAQYWLGCPAPGHL</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ProteinName_SPARE     Peptide_SPARE Status_SPARE\n",
       "0    sp|P02751|FINC_HUMAN   VDVIPVNLPGEHGQR          bon\n",
       "1    sp|P02751|FINC_HUMAN        STTPDITGYR          bon\n",
       "2    sp|P02751|FINC_HUMAN    SYTITGLQPGTDYK          bon\n",
       "3    sp|P02751|FINC_HUMAN       IYLYTLNDNAR          bon\n",
       "4    sp|P04114|APOB_HUMAN        TGISPLALIK          bon\n",
       "..                    ...               ...          ...\n",
       "150  sp|P02743|SAMP_HUMAN        VGEYSLYIGR          bon\n",
       "151  sp|P04004|VTNC_HUMAN        GQYCYELDEK      mauvais\n",
       "152  sp|P04004|VTNC_HUMAN      FEDGVLDPDYPR          bon\n",
       "153  sp|P04004|VTNC_HUMAN  DWHGVPGQVDAAMAGR          bon\n",
       "154  sp|P04004|VTNC_HUMAN   SIAQYWLGCPAPGHL          bon\n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/data\"\n",
    "original_df = pd.read_csv(f'{data_path}/final_status_SPARE.csv')\n",
    "original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_ccs_feature(dataframe, model_manager):\n",
    "    \"\"\"\n",
    "    Encodes CCS features for a given DataFrame using a pretrained CCS encoder.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame containing peptide sequences and required metadata.\n",
    "        model_manager (ModelManager): Manager object providing access to the pretrained CCS model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Numpy array of encoded peptide features (shape: [num_samples, embedding_dim]).\n",
    "    \"\"\"\n",
    "    encoder = model_manager.ccs_model.model.ccs_encoder\n",
    "    encoded_features = []\n",
    "\n",
    "    for i in range(len(dataframe)):\n",
    "        row = dataframe.iloc[[i]]\n",
    "\n",
    "        # Extract amino acid index features\n",
    "        aa_indices = model_manager.ccs_model._get_26aa_indice_features(row)\n",
    "\n",
    "        # Extract modification features\n",
    "        mod_x = model_manager.ccs_model._get_mod_features(row)\n",
    "\n",
    "        # Extract charge (required for CCS model input)\n",
    "        charge = torch.tensor(row[\"charge\"].values)\n",
    "\n",
    "        # Encode the peptide representation using the encoder\n",
    "        with torch.no_grad():\n",
    "            row_encoded_features = encoder(aa_indices, mod_x, charge)\n",
    "\n",
    "        # Store the encoded representation as a NumPy array\n",
    "        encoded_features.append(row_encoded_features.squeeze(0).numpy())\n",
    "\n",
    "    encoded_features = np.array(encoded_features)\n",
    "    return encoded_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantotypic\n",
      "0    117\n",
      "1     38\n",
      "Name: count, dtype: int64\n",
      "3.0789473684210527\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe with the sequences and labels\n",
    "df = pd.DataFrame()\n",
    "df[\"sequence\"] = original_df[\"Peptide_SPARE\"]\n",
    "# column required for CCS model\n",
    "df[\"mods\"] = ''\n",
    "df[\"mod_sites\"] = ''\n",
    "df[\"nAA\"] = df.sequence.str.len()\n",
    "df[\"charge\"] = 0\n",
    "df[\"quantotypic\"] = original_df.apply(lambda row: 0 if row['Status_SPARE'] =='bon' else 1, axis=1)\n",
    "\n",
    "positive_df = df[df['quantotypic'] == 0]\n",
    "negative_df = df[df['quantotypic'] == 1]\n",
    "\n",
    "class_counts = df['quantotypic'].value_counts()\n",
    "max_len = df['sequence'].str.len().max()\n",
    "pos_weight = class_counts[0] / class_counts[1]\n",
    "print(class_counts)\n",
    "print(pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 1, 'max_features': 'log2'}\n",
      "0.5207055871258658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 1, 'max_features': 'log2'}\n",
      "0.47665149571854465\n",
      "Accuracy: 0.8065\n",
      "Precision: 1.0000\n",
      "Recall: 0.1429\n",
      "F1 Score: 0.2500\n",
      "ROC AUC: 0.5714\n",
      "PR AUC: 0.3364\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 5, 'max_features': 'sqrt'}\n",
      "0.47116841547871974\n",
      "Accuracy: 0.7742\n",
      "Precision: 0.6667\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.3636\n",
      "ROC AUC: 0.6033\n",
      "PR AUC: 0.3602\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 3, 'max_features': 'log2'}\n",
      "0.4153400993571272\n",
      "Accuracy: 0.7742\n",
      "Precision: 1.0000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2222\n",
      "ROC AUC: 0.5625\n",
      "PR AUC: 0.3508\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': None, 'max_features': None}\n",
      "0.5089559691989359\n",
      "Accuracy: 0.6774\n",
      "Precision: 0.3333\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2857\n",
      "ROC AUC: 0.5380\n",
      "PR AUC: 0.2769\n",
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 1, 'max_features': 'sqrt'}\n",
      "0.5001345220291242\n",
      "Accuracy: 0.5806\n",
      "Precision: 0.2000\n",
      "Recall: 0.2857\n",
      "F1 Score: 0.2353\n",
      "ROC AUC: 0.4762\n",
      "PR AUC: 0.2184\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 1, 'max_features': None}\n",
      "0.4395012406876626\n",
      "Accuracy: 0.6452\n",
      "Precision: 0.3000\n",
      "Recall: 0.4286\n",
      "F1 Score: 0.3529\n",
      "ROC AUC: 0.5685\n",
      "PR AUC: 0.2576\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 3, 'max_features': 'log2'}\n",
      "0.4348832885094495\n",
      "Accuracy: 0.6129\n",
      "Precision: 0.2500\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2500\n",
      "ROC AUC: 0.4946\n",
      "PR AUC: 0.2560\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 1, 'max_features': 'log2'}\n",
      "0.36944154441277205\n",
      "Accuracy: 0.6452\n",
      "Precision: 0.3333\n",
      "Recall: 0.3750\n",
      "F1 Score: 0.3529\n",
      "ROC AUC: 0.5571\n",
      "PR AUC: 0.2863\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 3, 'max_features': 'log2'}\n",
      "0.4846289049376611\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "count = 1\n",
    "\n",
    "# Trying with and without weighting\n",
    "for weighting in [False, True]:\n",
    "    temp_result_list = []\n",
    "    # loop over folds\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(df['sequence'], df['quantotypic'])):\n",
    "        # Split the data into training and test sets\n",
    "        train_df = df.iloc[train_idx]\n",
    "        test_df = df.iloc[test_idx]\n",
    "        print(f\"Fold: {fold}\")\n",
    "        print()\n",
    "\n",
    "        model_mgr = ModelManager()\n",
    "\n",
    "        # Prepare training and test data\n",
    "        X_train = encode_ccs_feature(train_df, model_mgr)\n",
    "        y_train = train_df['quantotypic'].values\n",
    "\n",
    "        X_test = encode_ccs_feature(test_df, model_mgr)\n",
    "        y_test = test_df['quantotypic'].values\n",
    "\n",
    "        # Param grid for RandomForestClassifier\n",
    "        param_grid = {\n",
    "            'max_depth': [None, 1, 3, 5, 6],\n",
    "            'max_features': ['sqrt', 'log2', None], # None => max feature = n features\n",
    "        }\n",
    "\n",
    "        # If weighting is True, add class_weight to the param_grid\n",
    "        if weighting:\n",
    "            rf = RandomForestClassifier(n_estimators=1000, random_state=42, class_weight='balanced')\n",
    "        else:\n",
    "            rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "        # Train the model using GridSearchCV\n",
    "        grid_search_rf = GridSearchCV(rf, param_grid, cv=5, scoring='average_precision', verbose=4, n_jobs=-1)\n",
    "        grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "        print(grid_search_rf.best_params_)\n",
    "        print(grid_search_rf.best_score_)\n",
    "\n",
    "        # Retrieve the best parameters\n",
    "        best_params = grid_search_rf.best_params_\n",
    "\n",
    "        # Initialize a new RandomForestClassifier with the best parameters\n",
    "        if weighting:\n",
    "            best_rf = RandomForestClassifier(n_estimators=1000,\n",
    "                **best_params,\n",
    "                random_state=42,\n",
    "                class_weight='balanced'  # Include any additional arguments you used in GridSearchCV\n",
    "            )\n",
    "        else:\n",
    "            best_rf = RandomForestClassifier(n_estimators=1000,\n",
    "                **best_params,\n",
    "                random_state=42  # Include any additional arguments you used in GridSearchCV\n",
    "            )\n",
    "\n",
    "        # Retrain the model on the entire training set\n",
    "        best_rf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = best_rf.predict(X_test)\n",
    "\n",
    "        # Evaluate the model using the provided eval function\n",
    "        accuracy, precision, recall, f1, roc_auc, pr_auc = utils.eval(y_test, y_pred)\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"pr_auc\": pr_auc\n",
    "        }\n",
    "\n",
    "        temp_result_list.append(metrics)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    accuracy_list = [result['accuracy'] for result in temp_result_list]\n",
    "    precision_list = [result['precision'] for result in temp_result_list]\n",
    "    recall_list = [result['recall'] for result in temp_result_list]\n",
    "    f1_list = [result['f1'] for result in temp_result_list]\n",
    "    roc_auc_list = [result['roc_auc'] for result in temp_result_list]\n",
    "    pr_auc_list = [result['pr_auc'] for result in temp_result_list]\n",
    "\n",
    "    metrics_summary = {\n",
    "        \"accuracy_mean\": np.mean(accuracy_list),\n",
    "        \"accuracy_std\": np.std(accuracy_list),\n",
    "        \"precision_mean\": np.mean(precision_list),\n",
    "        \"precision_std\": np.std(precision_list),\n",
    "        \"recall_mean\": np.mean(recall_list),\n",
    "        \"recall_std\": np.std(recall_list),\n",
    "        \"f1_mean\": np.mean(f1_list),\n",
    "        \"f1_std\": np.std(f1_list),\n",
    "        \"roc_auc_mean\": np.mean(roc_auc_list),\n",
    "        \"roc_auc_std\": np.std(roc_auc_list),\n",
    "        \"pr_auc_mean\": np.mean(pr_auc_list),\n",
    "        \"pr_auc_std\": np.std(pr_auc_list)\n",
    "    }\n",
    "\n",
    "    dict_save = {\n",
    "        \"weighting\": weighting,\n",
    "        \"oversampling\": False,\n",
    "        \"metrics_summary\": metrics_summary\n",
    "    }\n",
    "\n",
    "    path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/Results/ValidProtocol\"\n",
    "    utils.write_into_json(dict_save, f\"{path}/CCS_RF_experiment_{count}.json\")\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'sqrt'}\n",
      "0.485981244458688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'sqrt'}\n",
      "0.43731086641911493\n",
      "Accuracy: 0.8065\n",
      "Precision: 1.0000\n",
      "Recall: 0.1429\n",
      "F1 Score: 0.2500\n",
      "ROC AUC: 0.5714\n",
      "PR AUC: 0.3364\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': 'sqrt'}\n",
      "0.4325548091436838\n",
      "Accuracy: 0.7742\n",
      "Precision: 0.6667\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.3636\n",
      "ROC AUC: 0.6033\n",
      "PR AUC: 0.3602\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': None}\n",
      "0.3923907030972248\n",
      "Accuracy: 0.7742\n",
      "Precision: 0.6667\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.3636\n",
      "ROC AUC: 0.6033\n",
      "PR AUC: 0.3602\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': None, 'classifier__max_features': 'log2'}\n",
      "0.4928408245969492\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.5000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2000\n",
      "ROC AUC: 0.5408\n",
      "PR AUC: 0.2883\n"
     ]
    }
   ],
   "source": [
    "# New loop with oversampling using ImbPipeline\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "temp_result_list = []\n",
    "# loop over folds\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df['sequence'], df['quantotypic'])):\n",
    "    # Split the data into training and test sets\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "    print(f\"Fold: {fold}\")\n",
    "    print()\n",
    "\n",
    "    # Create a ModelManager instance\n",
    "    model_mgr = ModelManager()\n",
    "\n",
    "    # Prepare training and test data\n",
    "    X_train = encode_ccs_feature(train_df, model_mgr)\n",
    "    y_train = train_df['quantotypic'].values\n",
    "\n",
    "    X_test = encode_ccs_feature(test_df, model_mgr)\n",
    "    y_test = test_df['quantotypic'].values\n",
    "\n",
    "    # Param grid for RandomForestClassifier\n",
    "    param_grid = {\n",
    "    'classifier__max_depth': [None, 1, 3, 5, 6],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],  # None = use all the features\n",
    "    }\n",
    "\n",
    "    # Creating the pipeline with oversampling and RandomForestClassifier\n",
    "    pipeline = ImbPipeline([\n",
    "        ('oversampler', RandomOverSampler(random_state=42)),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=1000,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Train the model using GridSearchCV\n",
    "    grid_search_rf = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='average_precision',\n",
    "        verbose=4,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "    print(grid_search_rf.best_params_)\n",
    "    print(grid_search_rf.best_score_)\n",
    "\n",
    "    # Retrieve the best parameters\n",
    "    best_params = grid_search_rf.best_params_\n",
    "\n",
    "    best_rf = RandomForestClassifier(\n",
    "        n_estimators=1000, \n",
    "        **{k.split('__')[1]: v for k, v in best_params.items()}, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Retrain the model on the entire training set with oversampling\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using the provided eval function\n",
    "    accuracy, precision, recall, f1, roc_auc, pr_auc = utils.eval(y_test, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc\n",
    "    }\n",
    "\n",
    "    temp_result_list.append(metrics)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "accuracy_list = [result['accuracy'] for result in temp_result_list]\n",
    "precision_list = [result['precision'] for result in temp_result_list]\n",
    "recall_list = [result['recall'] for result in temp_result_list]\n",
    "f1_list = [result['f1'] for result in temp_result_list]\n",
    "roc_auc_list = [result['roc_auc'] for result in temp_result_list]\n",
    "pr_auc_list = [result['pr_auc'] for result in temp_result_list]\n",
    "\n",
    "metrics_summary = {\n",
    "    \"accuracy_mean\": np.mean(accuracy_list),\n",
    "    \"accuracy_std\": np.std(accuracy_list),\n",
    "    \"precision_mean\": np.mean(precision_list),\n",
    "    \"precision_std\": np.std(precision_list),\n",
    "    \"recall_mean\": np.mean(recall_list),\n",
    "    \"recall_std\": np.std(recall_list),\n",
    "    \"f1_mean\": np.mean(f1_list),\n",
    "    \"f1_std\": np.std(f1_list),\n",
    "    \"roc_auc_mean\": np.mean(roc_auc_list),\n",
    "    \"roc_auc_std\": np.std(roc_auc_list),\n",
    "    \"pr_auc_mean\": np.mean(pr_auc_list),\n",
    "    \"pr_auc_std\": np.std(pr_auc_list)\n",
    "}\n",
    "\n",
    "dict_save = {\n",
    "    \"weighting\": False,\n",
    "    \"oversampling\": True,\n",
    "    \"metrics_summary\": metrics_summary\n",
    "}\n",
    "\n",
    "path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/Results/ValidProtocol\"\n",
    "utils.write_into_json(dict_save, f\"{path}/CCS_RF_experiment_3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'sqrt'}\n",
      "0.485981244458688\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.4792\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'sqrt'}\n",
      "0.43731086641911493\n",
      "Accuracy: 0.7742\n",
      "Precision: 0.5000\n",
      "Recall: 0.1429\n",
      "F1 Score: 0.2222\n",
      "ROC AUC: 0.5506\n",
      "PR AUC: 0.2650\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': 'sqrt'}\n",
      "0.4325548091436838\n",
      "Accuracy: 0.7742\n",
      "Precision: 0.6667\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.3636\n",
      "ROC AUC: 0.6033\n",
      "PR AUC: 0.3602\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': None}\n",
      "0.3923907030972248\n",
      "Accuracy: 0.7742\n",
      "Precision: 1.0000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2222\n",
      "ROC AUC: 0.5625\n",
      "PR AUC: 0.3508\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': None, 'classifier__max_features': 'log2'}\n",
      "0.4928408245969492\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.5000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2000\n",
      "ROC AUC: 0.5408\n",
      "PR AUC: 0.2883\n",
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'sqrt'}\n",
      "0.485981244458688\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.4792\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'sqrt'}\n",
      "0.43731086641911493\n",
      "Accuracy: 0.7742\n",
      "Precision: 0.5000\n",
      "Recall: 0.1429\n",
      "F1 Score: 0.2222\n",
      "ROC AUC: 0.5506\n",
      "PR AUC: 0.2650\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': 'sqrt'}\n",
      "0.4325548091436838\n",
      "Accuracy: 0.7742\n",
      "Precision: 0.6667\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.3636\n",
      "ROC AUC: 0.6033\n",
      "PR AUC: 0.3602\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': None}\n",
      "0.3923907030972248\n",
      "Accuracy: 0.7742\n",
      "Precision: 1.0000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2222\n",
      "ROC AUC: 0.5625\n",
      "PR AUC: 0.3508\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': None, 'classifier__max_features': 'log2'}\n",
      "0.4928408245969492\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.5000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2000\n",
      "ROC AUC: 0.5408\n",
      "PR AUC: 0.2883\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "count = 1\n",
    "\n",
    "# Trying with and without weighting\n",
    "for weighting in [False, True]:\n",
    "    temp_result_list = []\n",
    "\n",
    "    # loop over folds\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(df['sequence'], df['quantotypic'])):\n",
    "        # Split the data into training and test sets\n",
    "        train_df = df.iloc[train_idx]\n",
    "        test_df = df.iloc[test_idx]\n",
    "        print(f\"Fold: {fold}\")\n",
    "        print()\n",
    "\n",
    "        # Create a ModelManager instance\n",
    "        model_mgr = ModelManager()\n",
    "\n",
    "        # Prepare training and test data\n",
    "        X_train = encode_ccs_feature(train_df, model_mgr)\n",
    "        y_train = train_df['quantotypic'].values\n",
    "\n",
    "        X_test = encode_ccs_feature(test_df, model_mgr)\n",
    "        y_test = test_df['quantotypic'].values\n",
    "\n",
    "        # Param grid for XGBClassifier\n",
    "        param_grid = {\n",
    "            'max_depth': [None, 1, 3, 5, 6],              # Maximum tree depth, max 7\n",
    "            'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "        }\n",
    "\n",
    "        # If weighting is True, add scale_pos_weight to the param_grid\n",
    "        if weighting:\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=1000,\n",
    "                scale_pos_weight=pos_weight,  # Compensation du dÃ©sÃ©quilibre\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=1000,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        # Train the model using GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grid, cv=5, scoring=\"average_precision\", verbose=4, n_jobs=-1\n",
    "        )\n",
    "        grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "        print(grid_search_rf.best_params_)\n",
    "        print(grid_search_rf.best_score_)\n",
    "\n",
    "        # Retrieve the best parameters\n",
    "        best_params = grid_search_rf.best_params_\n",
    "\n",
    "        # Initialize a new RandomForestClassifier with the best parameters\n",
    "        if weighting:\n",
    "            best_model = XGBClassifier(\n",
    "                n_estimators=1000,\n",
    "                scale_pos_weight=pos_weight,\n",
    "                random_state=42,\n",
    "                **best_params\n",
    "            )\n",
    "        else:\n",
    "            best_model = XGBClassifier(\n",
    "                n_estimators=1000,\n",
    "                random_state=42,\n",
    "                **best_params\n",
    "            )\n",
    "\n",
    "        # Retrain the model on the entire training set\n",
    "        best_rf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = best_rf.predict(X_test)\n",
    "\n",
    "        # Evaluate the model using the provided eval function\n",
    "        accuracy, precision, recall, f1, roc_auc, pr_auc = utils.eval(y_test, y_pred)\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"pr_auc\": pr_auc\n",
    "        }\n",
    "\n",
    "        temp_result_list.append(metrics)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    accuracy_list = [result['accuracy'] for result in temp_result_list]\n",
    "    precision_list = [result['precision'] for result in temp_result_list]\n",
    "    recall_list = [result['recall'] for result in temp_result_list]\n",
    "    f1_list = [result['f1'] for result in temp_result_list]\n",
    "    roc_auc_list = [result['roc_auc'] for result in temp_result_list]\n",
    "    pr_auc_list = [result['pr_auc'] for result in temp_result_list]\n",
    "\n",
    "    metrics_summary = {\n",
    "        \"accuracy_mean\": np.mean(accuracy_list),\n",
    "        \"accuracy_std\": np.std(accuracy_list),\n",
    "        \"precision_mean\": np.mean(precision_list),\n",
    "        \"precision_std\": np.std(precision_list),\n",
    "        \"recall_mean\": np.mean(recall_list),\n",
    "        \"recall_std\": np.std(recall_list),\n",
    "        \"f1_mean\": np.mean(f1_list),\n",
    "        \"f1_std\": np.std(f1_list),\n",
    "        \"roc_auc_mean\": np.mean(roc_auc_list),\n",
    "        \"roc_auc_std\": np.std(roc_auc_list),\n",
    "        \"pr_auc_mean\": np.mean(pr_auc_list),\n",
    "        \"pr_auc_std\": np.std(pr_auc_list)\n",
    "    }\n",
    "\n",
    "    dict_save = {\n",
    "        \"weighting\": weighting,\n",
    "        \"oversampling\": False,\n",
    "        \"metrics_summary\": metrics_summary\n",
    "    }\n",
    "\n",
    "    path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/Results/ValidProtocol\"\n",
    "    utils.write_into_json(dict_save, f\"{path}/CCS_XGB_experiment_{count}.json\")\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'sqrt'}\n",
      "0.485981244458688\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.4792\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'sqrt'}\n",
      "0.43731086641911493\n",
      "Accuracy: 0.7742\n",
      "Precision: 0.5000\n",
      "Recall: 0.1429\n",
      "F1 Score: 0.2222\n",
      "ROC AUC: 0.5506\n",
      "PR AUC: 0.2650\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': 'sqrt'}\n",
      "0.4325548091436838\n",
      "Accuracy: 0.7742\n",
      "Precision: 0.6667\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.3636\n",
      "ROC AUC: 0.6033\n",
      "PR AUC: 0.3602\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': None}\n",
      "0.3923907030972248\n",
      "Accuracy: 0.7742\n",
      "Precision: 1.0000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2222\n",
      "ROC AUC: 0.5625\n",
      "PR AUC: 0.3508\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': None, 'classifier__max_features': 'log2'}\n",
      "0.4928408245969492\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.5000\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2000\n",
      "ROC AUC: 0.5408\n",
      "PR AUC: 0.2883\n"
     ]
    }
   ],
   "source": [
    "# New loop with oversampling using ImbPipeline\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "temp_result_list = []\n",
    "# loop over folds\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df['sequence'], df['quantotypic'])):\n",
    "    # Split the data into training and test sets\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "    print(f\"Fold: {fold}\")\n",
    "    print()\n",
    "\n",
    "    # Create a ModelManager instance\n",
    "    model_mgr = ModelManager()\n",
    "\n",
    "    # Prepare training and test data\n",
    "    X_train = encode_ccs_feature(train_df, model_mgr)\n",
    "    y_train = train_df['quantotypic'].values\n",
    "\n",
    "    X_test = encode_ccs_feature(test_df, model_mgr)\n",
    "    y_test = test_df['quantotypic'].values\n",
    "\n",
    "    # Param grid for RandomForestClassifier\n",
    "    param_grid = {\n",
    "        'classifier__max_depth': [None, 1, 3, 5, 6], \n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4], \n",
    "    }\n",
    "\n",
    "    # Creating the pipeline with oversampling and XGBClassifier\n",
    "    pipeline = ImbPipeline([\n",
    "        ('oversampler', RandomOverSampler(random_state=42)), \n",
    "        ('classifier', XGBClassifier(\n",
    "            n_estimators=1000, \n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Train the model using GridSearchCV\n",
    "    grid_search_xgb = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=5, \n",
    "        scoring='average_precision',\n",
    "        verbose=4,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "    print(grid_search_rf.best_params_)\n",
    "    print(grid_search_rf.best_score_)\n",
    "\n",
    "    # Retrieve the best parameters\n",
    "    best_params = grid_search_rf.best_params_\n",
    "\n",
    "    best_xgb = XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        random_state=42,\n",
    "        **best_params \n",
    "    )\n",
    "\n",
    "    # Retrain the model on the entire training set with oversampling\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using the provided eval function\n",
    "    accuracy, precision, recall, f1, roc_auc, pr_auc = utils.eval(y_test, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc\n",
    "    }\n",
    "\n",
    "    temp_result_list.append(metrics)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "accuracy_list = [result['accuracy'] for result in temp_result_list]\n",
    "precision_list = [result['precision'] for result in temp_result_list]\n",
    "recall_list = [result['recall'] for result in temp_result_list]\n",
    "f1_list = [result['f1'] for result in temp_result_list]\n",
    "roc_auc_list = [result['roc_auc'] for result in temp_result_list]\n",
    "pr_auc_list = [result['pr_auc'] for result in temp_result_list]\n",
    "\n",
    "metrics_summary = {\n",
    "    \"accuracy_mean\": np.mean(accuracy_list),\n",
    "    \"accuracy_std\": np.std(accuracy_list),\n",
    "    \"precision_mean\": np.mean(precision_list),\n",
    "    \"precision_std\": np.std(precision_list),\n",
    "    \"recall_mean\": np.mean(recall_list),\n",
    "    \"recall_std\": np.std(recall_list),\n",
    "    \"f1_mean\": np.mean(f1_list),\n",
    "    \"f1_std\": np.std(f1_list),\n",
    "    \"roc_auc_mean\": np.mean(roc_auc_list),\n",
    "    \"roc_auc_std\": np.std(roc_auc_list),\n",
    "    \"pr_auc_mean\": np.mean(pr_auc_list),\n",
    "    \"pr_auc_std\": np.std(pr_auc_list)\n",
    "}\n",
    "\n",
    "dict_save = {\n",
    "    \"weighting\": False,\n",
    "    \"oversampling\": True,\n",
    "    \"metrics_summary\": metrics_summary\n",
    "}\n",
    "\n",
    "path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/Results/ValidProtocol\"\n",
    "utils.write_into_json(dict_save, f\"{path}/CCS_XGB_experiment_3.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
