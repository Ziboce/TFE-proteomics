{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import esm \n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM2(\n",
      "  (embed_tokens): Embedding(33, 320, padding_idx=1)\n",
      "  (layers): ModuleList(\n",
      "    (0-5): 6 x TransformerLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (k_proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (v_proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (q_proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (rot_emb): RotaryEmbedding()\n",
      "      )\n",
      "      (self_attn_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (final_layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (contact_head): ContactPredictionHead(\n",
      "    (regression): Linear(in_features=120, out_features=1, bias=True)\n",
      "    (activation): Sigmoid()\n",
      "  )\n",
      "  (emb_layer_norm_after): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): RobertaLMHead(\n",
      "    (dense): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained model\n",
    "pretrained_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "\n",
    "# Print the structure to confirm the components\n",
    "print(pretrained_model, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProteinName_SPARE</th>\n",
       "      <th>Peptide_SPARE</th>\n",
       "      <th>Status_SPARE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>VDVIPVNLPGEHGQR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>STTPDITGYR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>SYTITGLQPGTDYK</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P02751|FINC_HUMAN</td>\n",
       "      <td>IYLYTLNDNAR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|P04114|APOB_HUMAN</td>\n",
       "      <td>TGISPLALIK</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>sp|P02743|SAMP_HUMAN</td>\n",
       "      <td>VGEYSLYIGR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>GQYCYELDEK</td>\n",
       "      <td>mauvais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>FEDGVLDPDYPR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>DWHGVPGQVDAAMAGR</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>sp|P04004|VTNC_HUMAN</td>\n",
       "      <td>SIAQYWLGCPAPGHL</td>\n",
       "      <td>bon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ProteinName_SPARE     Peptide_SPARE Status_SPARE\n",
       "0    sp|P02751|FINC_HUMAN   VDVIPVNLPGEHGQR          bon\n",
       "1    sp|P02751|FINC_HUMAN        STTPDITGYR          bon\n",
       "2    sp|P02751|FINC_HUMAN    SYTITGLQPGTDYK          bon\n",
       "3    sp|P02751|FINC_HUMAN       IYLYTLNDNAR          bon\n",
       "4    sp|P04114|APOB_HUMAN        TGISPLALIK          bon\n",
       "..                    ...               ...          ...\n",
       "150  sp|P02743|SAMP_HUMAN        VGEYSLYIGR          bon\n",
       "151  sp|P04004|VTNC_HUMAN        GQYCYELDEK      mauvais\n",
       "152  sp|P04004|VTNC_HUMAN      FEDGVLDPDYPR          bon\n",
       "153  sp|P04004|VTNC_HUMAN  DWHGVPGQVDAAMAGR          bon\n",
       "154  sp|P04004|VTNC_HUMAN   SIAQYWLGCPAPGHL          bon\n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/data\"\n",
    "original_df = pd.read_csv(f'{data_path}/final_status_SPARE.csv')\n",
    "original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantotypic\n",
      "0    117\n",
      "1     38\n",
      "Name: count, dtype: int64\n",
      "3.0789473684210527\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe with the sequences and labels\n",
    "df = pd.DataFrame()\n",
    "df[\"sequence\"] = original_df[\"Peptide_SPARE\"]\n",
    "df[\"quantotypic\"] = original_df.apply(lambda row: 0 if row['Status_SPARE'] =='bon' else 1, axis=1)\n",
    "\n",
    "positive_df = df[df['quantotypic'] == 0]\n",
    "negative_df = df[df['quantotypic'] == 1]\n",
    "\n",
    "class_counts = df['quantotypic'].value_counts()\n",
    "max_len = df['sequence'].str.len().max()\n",
    "pos_weight = class_counts[0] / class_counts[1]\n",
    "print(class_counts)\n",
    "print(pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 320)\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(sequences, model, batch_converter):\n",
    "    \"\"\"\n",
    "    Computes sequence embeddings from a pretrained ESM model using the specified representation layer.\n",
    "\n",
    "    Args:\n",
    "        sequences (list of str): List of amino acid sequences.\n",
    "        model (torch.nn.Module): Pretrained ESM model.\n",
    "        batch_converter (callable): Function that converts (ID, sequence) pairs into tokenized inputs.\n",
    "\n",
    "    Returns:\n",
    "        list of np.ndarray: List of mean residue embeddings for each sequence.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Convert sequences to batch tokens using the ESM batch converter\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(\n",
    "            [(f\"seq{i}\", seq) for i, seq in enumerate(sequences)]\n",
    "        )\n",
    "\n",
    "        # Get representations from a specific layer\n",
    "        results = model(batch_tokens, repr_layers=[6])\n",
    "        token_representations = results[\"representations\"][6]\n",
    "\n",
    "        for i, (_, seq) in enumerate(zip(batch_strs, sequences)):\n",
    "            # Compute mean of residue representations (excluding [CLS] and padding)\n",
    "            seq_embedding = token_representations[i, 1: len(seq) + 1].mean(0)\n",
    "            embeddings.append(seq_embedding.cpu().numpy())\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Extract embeddings for the sequences\n",
    "sequences = df['sequence'].tolist()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "embeddings = get_embeddings(sequences, pretrained_model, batch_converter)\n",
    "\n",
    "df[\"embedding\"] = embeddings\n",
    "embeddings = np.array(embeddings)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': None, 'max_features': 'log2'}\n",
      "0.3874379517889027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 3, 'max_features': None}\n",
      "0.4241602681754116\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.4792\n",
      "PR AUC: 0.2258\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': None, 'max_features': None}\n",
      "0.42361515903543767\n",
      "Accuracy: 0.6129\n",
      "Precision: 0.2500\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2500\n",
      "ROC AUC: 0.4946\n",
      "PR AUC: 0.2560\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 1, 'max_features': None}\n",
      "0.4098092632341858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 3, 'max_features': None}\n",
      "0.40082817337461296\n",
      "Accuracy: 0.7097\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.4783\n",
      "PR AUC: 0.2581\n",
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 1, 'max_features': None}\n",
      "0.45721282215090253\n",
      "Accuracy: 0.5806\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.3750\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 5, 'max_features': None}\n",
      "0.39727489501434277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 3, 'max_features': None}\n",
      "0.4175011246063877\n",
      "Accuracy: 0.6452\n",
      "Precision: 0.2857\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2667\n",
      "ROC AUC: 0.5163\n",
      "PR AUC: 0.2650\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 1, 'max_features': 'sqrt'}\n",
      "0.35164713182999624\n",
      "Accuracy: 0.6129\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.4130\n",
      "PR AUC: 0.2581\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'max_depth': 1, 'max_features': None}\n",
      "0.37556051396144274\n",
      "Accuracy: 0.6129\n",
      "Precision: 0.2500\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2500\n",
      "ROC AUC: 0.4946\n",
      "PR AUC: 0.2560\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "count = 1\n",
    "\n",
    "# Trying with and without weighting\n",
    "for weighting in [False, True]:\n",
    "    temp_result_list = []\n",
    "    # loop over the folds\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(df['sequence'], df['quantotypic'])):\n",
    "        # Split the data into training and test sets\n",
    "        train_df = df.iloc[train_idx]\n",
    "        test_df = df.iloc[test_idx]\n",
    "        print(f\"Fold: {fold}\")\n",
    "        print()\n",
    "\n",
    "        # Load the pretrained model and batch converter\n",
    "        pretrained_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "        batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "        # Get the embeddings for the training and test sets\n",
    "        train_sequences = train_df['sequence'].tolist()\n",
    "        train_embeddings = get_embeddings(train_sequences, pretrained_model, batch_converter)\n",
    "        X_train = np.vstack(train_embeddings)\n",
    "        y_train = train_df['quantotypic'].values\n",
    "\n",
    "        test_sequences = test_df['sequence'].tolist()\n",
    "        test_embeddings = get_embeddings(test_sequences, pretrained_model, batch_converter)\n",
    "        X_test = np.vstack(test_embeddings)\n",
    "        y_test = test_df['quantotypic'].values\n",
    "\n",
    "        # Param grid for RandomForestClassifier\n",
    "        param_grid = {\n",
    "            'max_depth': [None, 1, 3, 5, 6],\n",
    "            'max_features': ['sqrt', 'log2', None], # None => max feature = n features\n",
    "        }\n",
    "\n",
    "        # if weighting is True, add class_weight to the classifier\n",
    "        if weighting:\n",
    "            rf = RandomForestClassifier(n_estimators=1000, random_state=42, class_weight='balanced')\n",
    "        else:\n",
    "            rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "        # Train the model using GridSearchCV\n",
    "        grid_search_rf = GridSearchCV(rf, param_grid, cv=5, scoring='average_precision', verbose=4, n_jobs=-1)\n",
    "        grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "        print(grid_search_rf.best_params_)\n",
    "        print(grid_search_rf.best_score_)\n",
    "\n",
    "        # Retrieve the best parameters\n",
    "        best_params = grid_search_rf.best_params_\n",
    "\n",
    "        # Initialize a new RandomForestClassifier with the best parameters\n",
    "        if weighting:\n",
    "            best_rf = RandomForestClassifier(n_estimators=1000,\n",
    "                **best_params,\n",
    "                random_state=42,\n",
    "                class_weight='balanced'\n",
    "            )\n",
    "        else:\n",
    "            best_rf = RandomForestClassifier(n_estimators=1000,\n",
    "                **best_params,\n",
    "                random_state=42 \n",
    "            )\n",
    "\n",
    "        # Retrain the model on the entire training set\n",
    "        best_rf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = best_rf.predict(X_test)\n",
    "\n",
    "        # Evaluate the model using the provided eval function\n",
    "        accuracy, precision, recall, f1, roc_auc, pr_auc = utils.eval(y_test, y_pred)\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"pr_auc\": pr_auc\n",
    "        }\n",
    "\n",
    "        temp_result_list.append(metrics)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    accuracy_list = [result['accuracy'] for result in temp_result_list]\n",
    "    precision_list = [result['precision'] for result in temp_result_list]\n",
    "    recall_list = [result['recall'] for result in temp_result_list]\n",
    "    f1_list = [result['f1'] for result in temp_result_list]\n",
    "    roc_auc_list = [result['roc_auc'] for result in temp_result_list]\n",
    "    pr_auc_list = [result['pr_auc'] for result in temp_result_list]\n",
    "\n",
    "    metrics_summary = {\n",
    "        \"accuracy_mean\": np.mean(accuracy_list),\n",
    "        \"accuracy_std\": np.std(accuracy_list),\n",
    "        \"precision_mean\": np.mean(precision_list),\n",
    "        \"precision_std\": np.std(precision_list),\n",
    "        \"recall_mean\": np.mean(recall_list),\n",
    "        \"recall_std\": np.std(recall_list),\n",
    "        \"f1_mean\": np.mean(f1_list),\n",
    "        \"f1_std\": np.std(f1_list),\n",
    "        \"roc_auc_mean\": np.mean(roc_auc_list),\n",
    "        \"roc_auc_std\": np.std(roc_auc_list),\n",
    "        \"pr_auc_mean\": np.mean(pr_auc_list),\n",
    "        \"pr_auc_std\": np.std(pr_auc_list)\n",
    "    }\n",
    "\n",
    "    dict_save = {\n",
    "        \"weighting\": weighting,\n",
    "        \"oversampling\": False,\n",
    "        \"metrics_summary\": metrics_summary\n",
    "    }\n",
    "\n",
    "    path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/Results/ValidProtocol\"\n",
    "    utils.write_into_json(dict_save, f\"{path}/ESM_RF_experiment_{count}.json\")\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'log2'}\n",
      "0.43270336632178735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': None}\n",
      "0.39321747346281505\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.4792\n",
      "PR AUC: 0.2258\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 6, 'classifier__max_features': 'log2'}\n",
      "0.42331495960752924\n",
      "Accuracy: 0.7097\n",
      "Precision: 0.4000\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.3077\n",
      "ROC AUC: 0.5598\n",
      "PR AUC: 0.2935\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': None}\n",
      "0.36569407902612233\n",
      "Accuracy: 0.6129\n",
      "Precision: 0.1667\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.1429\n",
      "ROC AUC: 0.4538\n",
      "PR AUC: 0.2466\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'log2'}\n",
      "0.38883937527900375\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# New loop with oversampling using ImbPipeline\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "temp_result_list = []\n",
    "# loop over folds\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df['sequence'], df['quantotypic'])):\n",
    "    # Split the data into training and test sets\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "    print(f\"Fold: {fold}\")\n",
    "    print()\n",
    "\n",
    "    # Load the pretrained model and batch converter\n",
    "    pretrained_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "    # Get the embeddings for the training and test sets\n",
    "    train_sequences = train_df['sequence'].tolist()\n",
    "    train_embeddings = get_embeddings(train_sequences, pretrained_model, batch_converter)\n",
    "    X_train = np.vstack(train_embeddings)\n",
    "    y_train = train_df['quantotypic'].values\n",
    "\n",
    "    test_sequences = test_df['sequence'].tolist()\n",
    "    test_embeddings = get_embeddings(test_sequences, pretrained_model, batch_converter)\n",
    "    X_test = np.vstack(test_embeddings)\n",
    "    y_test = test_df['quantotypic'].values\n",
    "\n",
    "    # Param grid for RandomForestClassifier\n",
    "    param_grid = {\n",
    "    'classifier__max_depth': [None, 1, 3, 5, 6],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],  # None = utiliser toutes les features\n",
    "    }\n",
    "\n",
    "    # Create the pipeline with oversampling and classifier\n",
    "    pipeline = ImbPipeline([\n",
    "        ('oversampler', RandomOverSampler(random_state=42)), \n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=1000, \n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Training the model using GridSearchCV\n",
    "    grid_search_rf = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,  # Validation croisée avec 5 splits\n",
    "        scoring='average_precision',\n",
    "        verbose=4,  # Affiche la progression\n",
    "        n_jobs=-1  # Utilise tous les cœurs disponibles\n",
    "    )\n",
    "\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "    print(grid_search_rf.best_params_)\n",
    "    print(grid_search_rf.best_score_)\n",
    "\n",
    "    # Retrieve the best parameters\n",
    "    best_params = grid_search_rf.best_params_\n",
    "\n",
    "    best_rf = RandomForestClassifier(\n",
    "        n_estimators=1000,  # Nombre d'arbres\n",
    "        **{k.split('__')[1]: v for k, v in best_params.items()}, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Retrain the model on the entire training set with oversampling\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using the provided eval function\n",
    "    accuracy, precision, recall, f1, roc_auc, pr_auc = utils.eval(y_test, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc\n",
    "    }\n",
    "\n",
    "    temp_result_list.append(metrics)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "accuracy_list = [result['accuracy'] for result in temp_result_list]\n",
    "precision_list = [result['precision'] for result in temp_result_list]\n",
    "recall_list = [result['recall'] for result in temp_result_list]\n",
    "f1_list = [result['f1'] for result in temp_result_list]\n",
    "roc_auc_list = [result['roc_auc'] for result in temp_result_list]\n",
    "pr_auc_list = [result['pr_auc'] for result in temp_result_list]\n",
    "\n",
    "metrics_summary = {\n",
    "    \"accuracy_mean\": np.mean(accuracy_list),\n",
    "    \"accuracy_std\": np.std(accuracy_list),\n",
    "    \"precision_mean\": np.mean(precision_list),\n",
    "    \"precision_std\": np.std(precision_list),\n",
    "    \"recall_mean\": np.mean(recall_list),\n",
    "    \"recall_std\": np.std(recall_list),\n",
    "    \"f1_mean\": np.mean(f1_list),\n",
    "    \"f1_std\": np.std(f1_list),\n",
    "    \"roc_auc_mean\": np.mean(roc_auc_list),\n",
    "    \"roc_auc_std\": np.std(roc_auc_list),\n",
    "    \"pr_auc_mean\": np.mean(pr_auc_list),\n",
    "    \"pr_auc_std\": np.std(pr_auc_list)\n",
    "}\n",
    "\n",
    "dict_save = {\n",
    "    \"weighting\": False,\n",
    "    \"oversampling\": True,\n",
    "    \"metrics_summary\": metrics_summary\n",
    "}\n",
    "\n",
    "path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/Results/ValidProtocol\"\n",
    "utils.write_into_json(dict_save, f\"{path}/ESM_RF_experiment_3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'log2'}\n",
      "0.43270336632178735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': None}\n",
      "0.39321747346281505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 6, 'classifier__max_features': 'log2'}\n",
      "0.42331495960752924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': None}\n",
      "0.36569407902612233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'log2'}\n",
      "0.38883937527900375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n",
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'log2'}\n",
      "0.43270336632178735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': None}\n",
      "0.39321747346281505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 6, 'classifier__max_features': 'log2'}\n",
      "0.42331495960752924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': None}\n",
      "0.36569407902612233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'log2'}\n",
      "0.38883937527900375\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "count = 1\n",
    "\n",
    "# Trying with and without weighting\n",
    "for weighting in [False, True]:\n",
    "    temp_result_list = []\n",
    "\n",
    "    # loop over the folds\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(df['sequence'], df['quantotypic'])):\n",
    "        # Split the data into training and test sets\n",
    "        train_df = df.iloc[train_idx]\n",
    "        test_df = df.iloc[test_idx]\n",
    "        print(f\"Fold: {fold}\")\n",
    "        print()\n",
    "\n",
    "        # Load the pretrained model and batch converter\n",
    "        pretrained_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "        batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "        # Get the embeddings for the training and test sets\n",
    "        train_sequences = train_df['sequence'].tolist()\n",
    "        train_embeddings = get_embeddings(train_sequences, pretrained_model, batch_converter)\n",
    "        X_train = np.vstack(train_embeddings)\n",
    "        y_train = train_df['quantotypic'].values\n",
    "\n",
    "        test_sequences = test_df['sequence'].tolist()\n",
    "        test_embeddings = get_embeddings(test_sequences, pretrained_model, batch_converter)\n",
    "        X_test = np.vstack(test_embeddings)\n",
    "        y_test = test_df['quantotypic'].values\n",
    "\n",
    "        # Param grid for XGBClassifier\n",
    "        param_grid = {\n",
    "            'max_depth': [None, 1, 3, 5, 6],              \n",
    "            'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "        }\n",
    "\n",
    "        # if weighting is True, add scale_pos_weight to the classifier\n",
    "        if weighting:\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=1000,\n",
    "                scale_pos_weight=pos_weight, \n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=1000,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        # Train the model using GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grid, cv=5, scoring=\"average_precision\", verbose=4, n_jobs=-1\n",
    "        )\n",
    "        grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "        print(grid_search_rf.best_params_)\n",
    "        print(grid_search_rf.best_score_)\n",
    "\n",
    "        # Retrieve the best parameters\n",
    "        best_params = grid_search_rf.best_params_\n",
    "\n",
    "        # Initialize a new XGBClassifier with the best parameters\n",
    "        if weighting:\n",
    "            best_model = XGBClassifier(\n",
    "                n_estimators=1000,\n",
    "                scale_pos_weight=pos_weight,\n",
    "                random_state=42,\n",
    "                **best_params\n",
    "            )\n",
    "        else:\n",
    "            best_model = XGBClassifier(\n",
    "                n_estimators=1000,\n",
    "                random_state=42,\n",
    "                **best_params\n",
    "            )\n",
    "\n",
    "        # Retrain the model on the entire training set\n",
    "        best_rf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = best_rf.predict(X_test)\n",
    "\n",
    "        # Evaluate the model using the provided eval function\n",
    "        accuracy, precision, recall, f1, roc_auc, pr_auc = utils.eval(y_test, y_pred)\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"pr_auc\": pr_auc\n",
    "        }\n",
    "\n",
    "        temp_result_list.append(metrics)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    accuracy_list = [result['accuracy'] for result in temp_result_list]\n",
    "    precision_list = [result['precision'] for result in temp_result_list]\n",
    "    recall_list = [result['recall'] for result in temp_result_list]\n",
    "    f1_list = [result['f1'] for result in temp_result_list]\n",
    "    roc_auc_list = [result['roc_auc'] for result in temp_result_list]\n",
    "    pr_auc_list = [result['pr_auc'] for result in temp_result_list]\n",
    "\n",
    "    metrics_summary = {\n",
    "        \"accuracy_mean\": np.mean(accuracy_list),\n",
    "        \"accuracy_std\": np.std(accuracy_list),\n",
    "        \"precision_mean\": np.mean(precision_list),\n",
    "        \"precision_std\": np.std(precision_list),\n",
    "        \"recall_mean\": np.mean(recall_list),\n",
    "        \"recall_std\": np.std(recall_list),\n",
    "        \"f1_mean\": np.mean(f1_list),\n",
    "        \"f1_std\": np.std(f1_list),\n",
    "        \"roc_auc_mean\": np.mean(roc_auc_list),\n",
    "        \"roc_auc_std\": np.std(roc_auc_list),\n",
    "        \"pr_auc_mean\": np.mean(pr_auc_list),\n",
    "        \"pr_auc_std\": np.std(pr_auc_list)\n",
    "    }\n",
    "\n",
    "    dict_save = {\n",
    "        \"weighting\": weighting,\n",
    "        \"oversampling\": False,\n",
    "        \"metrics_summary\": metrics_summary\n",
    "    }\n",
    "\n",
    "    path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/Results/ValidProtocol\"\n",
    "    utils.write_into_json(dict_save, f\"{path}/ESM_XGB_experiment_{count}.json\")\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'log2'}\n",
      "0.43270336632178735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 1\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': None}\n",
      "0.39321747346281505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7742\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2258\n",
      "Fold: 2\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 6, 'classifier__max_features': 'log2'}\n",
      "0.42331495960752924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n",
      "Fold: 3\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': None}\n",
      "0.36569407902612233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n",
      "Fold: 4\n",
      "\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "{'classifier__max_depth': 1, 'classifier__max_features': 'log2'}\n",
      "0.38883937527900375\n",
      "Accuracy: 0.7419\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC AUC: 0.5000\n",
      "PR AUC: 0.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# New loop with oversampling using ImbPipeline\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "temp_result_list = []\n",
    "# loop over folds\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df['sequence'], df['quantotypic'])):\n",
    "    # Split the data into training and test sets\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "    print(f\"Fold: {fold}\")\n",
    "    print()\n",
    "\n",
    "    # Load the pretrained model and batch converter\n",
    "    pretrained_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "    # Get the embeddings for the training and test sets\n",
    "    train_sequences = train_df['sequence'].tolist()\n",
    "    train_embeddings = get_embeddings(train_sequences, pretrained_model, batch_converter)\n",
    "    X_train = np.vstack(train_embeddings)\n",
    "    y_train = train_df['quantotypic'].values\n",
    "\n",
    "    test_sequences = test_df['sequence'].tolist()\n",
    "    test_embeddings = get_embeddings(test_sequences, pretrained_model, batch_converter)\n",
    "    X_test = np.vstack(test_embeddings)\n",
    "    y_test = test_df['quantotypic'].values\n",
    "\n",
    "    # Param grid for XGBClassifier\n",
    "    param_grid = {\n",
    "        'classifier__max_depth': [None, 1, 3, 5, 6], \n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4], \n",
    "    }\n",
    "\n",
    "    # Create the pipeline with oversampling and classifier\n",
    "    pipeline = ImbPipeline([\n",
    "        ('oversampler', RandomOverSampler(random_state=42)), \n",
    "        ('classifier', XGBClassifier(\n",
    "            n_estimators=1000, \n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Training the model using GridSearchCV\n",
    "    grid_search_xgb = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,  \n",
    "        scoring='average_precision',\n",
    "        verbose=4,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "    print(grid_search_rf.best_params_)\n",
    "    print(grid_search_rf.best_score_)\n",
    "\n",
    "    # Retrieve the best parameters\n",
    "    best_params = grid_search_rf.best_params_\n",
    "\n",
    "    best_xgb = XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        random_state=42,\n",
    "        **best_params \n",
    "    )\n",
    "\n",
    "    # Retrain the model on the entire training set with oversampling\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using the provided eval function\n",
    "    accuracy, precision, recall, f1, roc_auc, pr_auc = utils.eval(y_test, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc\n",
    "    }\n",
    "\n",
    "    temp_result_list.append(metrics)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "accuracy_list = [result['accuracy'] for result in temp_result_list]\n",
    "precision_list = [result['precision'] for result in temp_result_list]\n",
    "recall_list = [result['recall'] for result in temp_result_list]\n",
    "f1_list = [result['f1'] for result in temp_result_list]\n",
    "roc_auc_list = [result['roc_auc'] for result in temp_result_list]\n",
    "pr_auc_list = [result['pr_auc'] for result in temp_result_list]\n",
    "\n",
    "metrics_summary = {\n",
    "    \"accuracy_mean\": np.mean(accuracy_list),\n",
    "    \"accuracy_std\": np.std(accuracy_list),\n",
    "    \"precision_mean\": np.mean(precision_list),\n",
    "    \"precision_std\": np.std(precision_list),\n",
    "    \"recall_mean\": np.mean(recall_list),\n",
    "    \"recall_std\": np.std(recall_list),\n",
    "    \"f1_mean\": np.mean(f1_list),\n",
    "    \"f1_std\": np.std(f1_list),\n",
    "    \"roc_auc_mean\": np.mean(roc_auc_list),\n",
    "    \"roc_auc_std\": np.std(roc_auc_list),\n",
    "    \"pr_auc_mean\": np.mean(pr_auc_list),\n",
    "    \"pr_auc_std\": np.std(pr_auc_list)\n",
    "}\n",
    "\n",
    "dict_save = {\n",
    "    \"weighting\": False,\n",
    "    \"oversampling\": True,\n",
    "    \"metrics_summary\": metrics_summary\n",
    "}\n",
    "\n",
    "path = \"C:/Users/Walraff/OneDrive - Universite de Liege/Documents/Ulg/Master2/TFE/Results/ValidProtocol\"\n",
    "utils.write_into_json(dict_save, f\"{path}/ESM_XGB_experiment_3.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
